{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HgOWtsJ8rUEH"
   },
   "source": [
    "# Estimation de l'ATE/CATE sur des données synthétiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "XWZ-_PbjrUEK"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import bernoulli\n",
    "import scipy as sp\n",
    "#from scipy import st\n",
    "from scipy import integrate\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "sns.set_context(\"paper\", font_scale=1.5, rc={\"lines.linewidth\": 1.5})\n",
    "plt.rcParams['figure.figsize'] = 10, 8\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Xj_Wz5NFKmO"
   },
   "outputs": [],
   "source": [
    "!pip install causalml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Zli_yoWuclrr"
   },
   "outputs": [],
   "source": [
    "import causalml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "stT8FysBrUEL"
   },
   "source": [
    "## Génération de données synthétiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9gPyMC5MrUEM"
   },
   "outputs": [],
   "source": [
    "def treatment_assign(Nobs, d, X, p):\n",
    "    '''\n",
    "    Input: \n",
    "    \n",
    "    p : score de propension.\n",
    "    Nobs : Nombre de lignes da la matrice X i.e. nombre de personnes.\n",
    "    \n",
    "    Output:\n",
    "    \n",
    "    W : Vecteur de taille Nobs contenant des 0 ou 1 pour désigner l'affectation du traitement.\n",
    "    '''\n",
    "    sigmoid = lambda x: 1/(1+np.exp(-x))\n",
    "    \n",
    "    omega = np.random.uniform(0, 1, (Nobs, d))\n",
    "    psi = np.random.uniform(0, 1, (Nobs, 1))\n",
    "\n",
    "    if p == None:\n",
    "      p = np.zeros(Nobs)\n",
    "      for i in range(Nobs):\n",
    "        p[i] = sigmoid(omega[i] @ X[i])\n",
    "      W = bernoulli.rvs(p, size = Nobs) \n",
    "    else:\n",
    "      W = bernoulli.rvs(p, size = Nobs) \n",
    "    \n",
    "    return W\n",
    "\n",
    "\n",
    "def causal_generation(Nobs, dim, beta, bias, f, g, p):\n",
    "    '''\n",
    "    Input :\n",
    "    \n",
    "    Nobs : Nombre de lignes da la matrice X i.e. nombre de personnes.\n",
    "    dim : Nombre de colonnes de la matrice X i.e. nombres de caractéristiques (features).\n",
    "    beta : Vecteur de dimension (2, dim).\n",
    "    bias : Vecteur de dimension (1, 2).\n",
    "    W : Vecteur de dimension (1, Nobs) contenant des 0 ou 1 pour désigner \n",
    "    l'affectation du traitement.\n",
    "    f et g sont des fonctions.\n",
    "    \n",
    "    Output:\n",
    "    \n",
    "    (X, Y, W) : Triplet contenant la matrice X des features, Y le vecteur des \n",
    "                résultats potentiels et W le vecteur de l'affectation du traitement.\n",
    "    '''\n",
    "    moy = np.zeros(dim)\n",
    "    var = np.eye(dim)\n",
    "    X = np.random.multivariate_normal(moy, var, Nobs)\n",
    "    Y = np.zeros(Nobs)\n",
    "\n",
    "    W = treatment_assign(Nobs, dim, X, p)\n",
    "\n",
    "    for i in range(Nobs):\n",
    "        bruit = np.random.normal(0, 1)\n",
    "        if W[i] == 0:\n",
    "            Y[i] = f(beta[0] @ X[i] + bias[0]) + bruit\n",
    "        if W[i] == 1:\n",
    "            Y[i] = g(beta[1] @ X[i] + bias[1]) + bruit\n",
    "            \n",
    "    return (X, W, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métalearners internes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O8cCtYY-rUEN"
   },
   "source": [
    "### S-learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "tAi-i1kOnOtR"
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "class SLearner(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\" Homemade SLearner class \"\"\"\n",
    "    \n",
    "    def __init__(self, base_estimator=LinearRegression()):\n",
    "        # init\n",
    "        self.estimator = base_estimator\n",
    "        \n",
    "    def fit(self, X, W, Y):\n",
    "        # Initiation des variables\n",
    "        self.X = X\n",
    "        self.W = W\n",
    "        self.Y = Y\n",
    "        self.features = np.hstack((self.X, self.W[:,np.newaxis]))\n",
    "        self.clf = self.estimator.fit(self.features, self.Y)\n",
    "\n",
    "    def predict_CATE(self, x):\n",
    "        # Complete the method      \n",
    "        self.Y_0_hat = self.clf.predict(np.c_[x, np.zeros(len(x))])\n",
    "        self.Y_1_hat = self.clf.predict(np.c_[x, np.ones(len(x))])\n",
    "        return self.Y_1_hat - self.Y_0_hat\n",
    "\n",
    "    def predict_ATE(self):\n",
    "        return (self.Y_1_hat - self.Y_0_hat).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FEvqUznWxMrf"
   },
   "source": [
    "### T-learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "B9Zl-vv30rHU"
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "class TLearner(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\" Homemade TLearner class \"\"\"\n",
    "    \n",
    "    def __init__(self, base_estimator0=LinearRegression(), base_estimator1=LinearRegression() ):\n",
    "        # init\n",
    "        self.estimator0 = base_estimator0\n",
    "        self.estimator1 = base_estimator1\n",
    "\n",
    "    def fit(self, X, W, Y):\n",
    "        # Initiation des variables\n",
    "        self.X = X\n",
    "        self.W = W\n",
    "        self.Y = Y\n",
    "        self.mu_0 = self.estimator0.fit(X[self.W==0,:], self.Y[self.W==0])\n",
    "        self.mu_1 = self.estimator1.fit(X[self.W==1,:], self.Y[self.W==1])\n",
    "\n",
    "    def predict_CATE(self, x):\n",
    "        # Complete the method         \n",
    "        self.Y_0_hat = self.mu_0.predict(x)\n",
    "        self.Y_1_hat = self.mu_1.predict(x)\n",
    "        return self.Y_1_hat - self.Y_0_hat\n",
    "\n",
    "    def predict_ATE(self):\n",
    "        return (self.Y_1_hat - self.Y_0_hat).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mpbCRF4wxSmw"
   },
   "source": [
    "### X-Learners ( a vérifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "class XLearner(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\" Homemade XLearner class \"\"\"\n",
    "    \n",
    "    def __init__(self, outcome_learner0 = LinearRegression(), outcome_learner1 = LinearRegression(), \n",
    "                 effect_learner0 = LinearRegression(), effect_learner1 = LinearRegression()):\n",
    "        # init\n",
    "        self.outcome_learner0 = outcome_learner0\n",
    "        self.outcome_learner1 = outcome_learner1\n",
    "        self.effect_learner0 = effect_learner0\n",
    "        self.effect_learner1 = effect_learner1\n",
    "\n",
    "    def fit(self, X, W, Y):\n",
    "        # Initiation des variables\n",
    "        self.X = X\n",
    "        self.W = W\n",
    "        self.Y = Y \n",
    "        \n",
    "        #Stage 1 : Estimate the average outcomes μ0(x) and  μ1(x)\n",
    "        self.mu_0 = self.outcome_learner0.fit(X[self.W==0,:], self.Y[self.W==0])\n",
    "        self.mu_1 = self.outcome_learner1.fit(X[self.W==1,:], self.Y[self.W==1])\n",
    "        \n",
    "        #Stage 2 : Impute the user level treatment effects\n",
    "        self.D0 = self.mu_1.predict(X[self.W==0,:]) - self.Y[self.W==0] \n",
    "        self.D1 = self.Y[self.W==1] - self.mu_0.predict(X[self.W==1,:])    \n",
    "        \n",
    "        #estimate τ1(x) = E[D1|X=x], and τ0(x) = E[D0|X=x] using machine learning models:\n",
    "        self.tau_0 = self.effect_learner0 .fit(X[self.W==0,:], self.D0)\n",
    "        self.tau_1 = self.effect_learner0 .fit(X[self.W==1,:], self.D1)\n",
    "        \n",
    "\n",
    "    def predict_CATE(self, x, p):\n",
    "        # Complete the method         \n",
    "        self.CATE_hat = p*self.tau_0.predict(x) + (1-p)*self.tau_1.predict(x)\n",
    "        return self.CATE_hat\n",
    "\n",
    "    def predict_ATE(self):\n",
    "        return (self.CATE_hat).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DR-Learners ( a vérifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "class DRLearner(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\" Homemade DRLearner class \"\"\"\n",
    "    \n",
    "    def __init__(self, model_regression = LinearRegression(), model_propensity = LogisticRegression(), \n",
    "                 model_final = LinearRegression()):\n",
    "        # init\n",
    "        self.model_regression = model_regression\n",
    "        self.model_propensity = model_propensity\n",
    "        self.model_final = model_final\n",
    "        \n",
    "\n",
    "    def fit(self, X, W, Y):\n",
    "        # Initiation des variables\n",
    "        self.X = X\n",
    "        self.W = W\n",
    "        self.Y = Y \n",
    "        \n",
    "        #Stage 1 : Regression of the outcomes μ(X,T) = E[Y|X,W,T]\n",
    "        self.features = np.hstack((self.X, self.W[:,np.newaxis]))\n",
    "        self.mu = self.model_regression.fit(self.features, self.Y)\n",
    "        \n",
    "        #Stage 1 : Model to estimate the propensity_score\n",
    "        self.model_propensity = CalibratedClassifierCV(self.model_propensity)\n",
    "        self.model_propensity.fit(self.X, self.W)\n",
    "        self.propensity = self.model_propensity.predict_proba(X)\n",
    "\n",
    "        #Stage 1 : predict Y_pred\n",
    "        self.Y_pred_0 = self.mu.predict(np.hstack((self.X, np.zeros((self.X.shape[0],1)))))\n",
    "        self.Y_pred_0 += (Y - self.Y_pred_0) * (1 - self.W) / self.propensity[:,0]\n",
    "        self.Y_pred_1 = self.mu.predict(np.hstack((self.X, np.ones((self.X.shape[0],1)))))\n",
    "        self.Y_pred_1 += (Y - self.Y_pred_1) * (self.W) / self.propensity[:,1]\n",
    "        \n",
    "        #Stage 2 : fit model final\n",
    "        self.model_final.fit(self.X, self.Y_pred_1 - self.Y_pred_0)\n",
    "        \n",
    "\n",
    "    def predict_CATE(self, x):\n",
    "        # Complete the method         \n",
    "        self.CATE_hat = self.model_final.predict(x)\n",
    "        return self.CATE_hat\n",
    "\n",
    "    def predict_ATE(self):\n",
    "        return (self.CATE_hat).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZIf7QInLeFIP"
   },
   "source": [
    "## Phase de test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JlTx_NDBy42f"
   },
   "source": [
    "### Initialisation des paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "3GNGiMt0y9cA"
   },
   "outputs": [],
   "source": [
    "N = 1000\n",
    "d = 2                                       # d = 2, afin de pouvoir être calculé par intégration et par Monte Carlo\n",
    "p = 0.5\n",
    "beta0 = np.random.uniform(1, 30, (1, d))\n",
    "beta1 = np.random.uniform(2000,4000, (1, d))\n",
    "beta = np.vstack((beta0,beta1))               # beta0 = beta1           \n",
    "bias = np.array([100,10])                 # beta0 = beta1, cas simple pour faciliter l'interprétation des résultats                              # Gamma0 != Gamma1, biais différent\n",
    "f = lambda x:x\n",
    "g = lambda x:x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6OhpvinNxUdk"
   },
   "source": [
    "### Générations des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "BLuyzerxeJPV",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Génération des données\n",
    "X, W, Y = causal_generation(N, d, beta, bias, f, g, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0HGXgVo5xa2M"
   },
   "source": [
    "### Prédictions des métalearners \"Team Filrouge\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6BVz8q9v3pnC"
   },
   "source": [
    "#### Slearners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_learner=LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gQHpwQc4mGf3",
    "outputId": "b4983705-e538-452e-d437-0a0c50071620",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Les dimensions du CATE = (1000,).\n",
      "- L'estimation de la valeur de l'ATE = -134.7533273948109.\n"
     ]
    }
   ],
   "source": [
    "slearner=SLearner(base_estimator=RandomForestRegressor())\n",
    "slearner.fit(X,W,Y)\n",
    "\n",
    "cate_hat_S = slearner.predict_CATE(X)\n",
    "print(\"- Les dimensions du CATE = {}.\".format(cate_hat_S.shape))\n",
    "\n",
    "ate_hat_S = slearner.predict_ATE()\n",
    "print(\"- L'estimation de la valeur de l'ATE = {}.\".format(ate_hat_S))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RmJV1Jy-3ve6"
   },
   "source": [
    "#### Tlearners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r1WmQRa33okq",
    "outputId": "e865c751-0b7a-4056-c20f-d0e030adb5bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Les dimensions du CATE = (1000,).\n",
      "- L'estimation de la valeur de l'ATE = -140.3146524921403.\n"
     ]
    }
   ],
   "source": [
    "tlearner=TLearner(base_estimator0=RandomForestRegressor(),base_estimator1=RandomForestRegressor())\n",
    "tlearner.fit(X,W,Y)\n",
    "\n",
    "cate_hat_T = tlearner.predict_CATE(X)\n",
    "print(\"- Les dimensions du CATE = {}.\".format(cate_hat_S.shape))\n",
    "\n",
    "ate_hat_T = tlearner.predict_ATE()\n",
    "print(\"- L'estimation de la valeur de l'ATE = {}.\".format(ate_hat_T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Xlearners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propensity_score(X, W, clf = LogisticRegression()):\n",
    "    # calibration of the classifier\n",
    "    cls = CalibratedClassifierCV(clf)\n",
    "\n",
    "    # training of the classifier\n",
    "    cls.fit(X, W)\n",
    "\n",
    "    # predicton of the classifier\n",
    "    propensity = cls.predict_proba(X)[:,1]\n",
    "\n",
    "    return propensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  5.,  17.,  57., 152., 216., 243., 169., 102.,  34.,   5.]),\n",
       " array([0.47974223, 0.48313819, 0.48653415, 0.48993011, 0.49332607,\n",
       "        0.49672204, 0.500118  , 0.50351396, 0.50690992, 0.51030588,\n",
       "        0.51370184]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "propensity=propensity_score(X, W)\n",
    "\n",
    "plt.hist(propensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Les dimensions du CATE = (1000,).\n",
      "- L'estimation de la valeur de l'ATE = -117.9375643984449.\n"
     ]
    }
   ],
   "source": [
    "xlearner=XLearner()\n",
    "xlearner.fit(X,W,Y)\n",
    "\n",
    "cate_hat_T = xlearner.predict_CATE(X, propensity)\n",
    "print(\"- Les dimensions du CATE = {}.\".format(cate_hat_S.shape))\n",
    "\n",
    "ate_hat_T = xlearner.predict_ATE()\n",
    "print(\"- L'estimation de la valeur de l'ATE = {}.\".format(ate_hat_T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DRlearners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 2), (1000,), (1000,))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, W.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Les dimensions du CATE = (1000,).\n",
      "- L'estimation de la valeur de l'ATE = -117.17779026622827.\n"
     ]
    }
   ],
   "source": [
    "drlearner=DRLearner()\n",
    "drlearner.fit(X,W,Y)\n",
    "\n",
    "cate_hat_T = drlearner.predict_CATE(X)\n",
    "print(\"- Les dimensions du CATE = {}.\".format(cate_hat_T.shape))\n",
    "\n",
    "ate_hat_T = drlearner.predict_ATE()\n",
    "print(\"- L'estimation de la valeur de l'ATE = {}.\".format(ate_hat_T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gq-vjom4xmRs"
   },
   "source": [
    "### Prédictions des métalearners \"Causal ML\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Tn-YCHA4L5r"
   },
   "source": [
    "#### Slearners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7naePgnBlxjE",
    "outputId": "97392a23-6e7c-4c4a-df2e-d4aca18181a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'estimation de la valeur de l'ATE (Linear Regression): -89.94 (-90.07, -89.82)\n"
     ]
    }
   ],
   "source": [
    "from causalml.inference.meta import LRSRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "\n",
    "lr = LRSRegressor()\n",
    "te, lb, ub = lr.estimate_ate(X, W, Y)\n",
    "print('L\\'estimation de la valeur de l\\'ATE (Linear Regression): {:.2f} ({:.2f}, {:.2f})'.format(te[0], lb[0], ub[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VeQ5ZgiJ4OQb"
   },
   "source": [
    "#### Tlearners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mzPAOp0h4Lac",
    "outputId": "458f9c1d-d1b2-41c1-c105-c187bf02d9e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'estimation de la valeur de l'ATE (XGBoost): -90.15 (-90.29, -90.01)\n"
     ]
    }
   ],
   "source": [
    "from causalml.inference.meta import XGBTRegressor\n",
    "\n",
    "xg = XGBTRegressor(random_state=42)\n",
    "te, lb, ub = xg.estimate_ate(X, W, Y)\n",
    "print('L\\'estimation de la valeur de l\\'ATE (XGBoost): {:.2f} ({:.2f}, {:.2f})'.format(te[0], lb[0], ub[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Xlearners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Treatment Effect (BaseXRegressor using XGBoost): -90.09 (-90.17, -90.00)\n"
     ]
    }
   ],
   "source": [
    "from causalml.inference.meta import BaseXRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "\n",
    "#le propensity score est calculé automatiquement par le modèle\n",
    "xl = BaseXRegressor(learner=XGBRegressor())\n",
    "te, lb, ub = xl.estimate_ate(X, treatment = W, y = Y, p = None)\n",
    "print('Average Treatment Effect (BaseXRegressor using XGBoost): {:.2f} ({:.2f}, {:.2f})'.format(te[0], lb[0], ub[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DRlearners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'estimation de la valeur de l'ATE (): -89.94)\n"
     ]
    }
   ],
   "source": [
    "import econml\n",
    "from econml.drlearner import DRLearner\n",
    "\n",
    "est = DRLearner()\n",
    "est.fit(Y, W, X=X, W=None)\n",
    "\n",
    "print('L\\'estimation de la valeur de l\\'ATE (): {:.2f})'.format(est.effect(X).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-89.99991764, -89.85861157, -89.86072109, -89.89158232,\n",
       "       -89.99023741, -89.89782743, -89.93376671, -89.89114295,\n",
       "       -89.87370599, -90.00406251, -89.97749091, -89.97982202,\n",
       "       -89.91720692, -90.00431766, -89.9322361 , -89.90536634,\n",
       "       -90.00246269, -89.97564614, -89.97471676, -89.9258119 ,\n",
       "       -89.97877369, -89.94122736, -89.89696851, -89.95226138,\n",
       "       -89.97274275, -89.98007958, -90.01294196, -90.00542782,\n",
       "       -89.9777517 , -89.9490885 , -89.88840983, -89.94404091,\n",
       "       -89.90687693, -89.99421525, -89.94455214, -89.94827335,\n",
       "       -89.88330134, -89.9178758 , -89.98220347, -89.99292206,\n",
       "       -89.95583195, -89.92277847, -89.96593238, -89.88252758,\n",
       "       -89.93668777, -89.95446105, -89.95426972, -89.90439393,\n",
       "       -89.87930565, -89.89787604, -89.97510299, -89.85632748,\n",
       "       -89.95907274, -89.9410762 , -89.95771734, -89.92413954,\n",
       "       -89.93652824, -89.91764982, -89.93952315, -89.93784984,\n",
       "       -89.89036811, -89.89431878, -89.9160789 , -89.94477072,\n",
       "       -89.96063949, -89.91746282, -89.97486582, -89.92801157,\n",
       "       -89.92116697, -89.91086285, -89.92659799, -89.9750176 ,\n",
       "       -89.9217811 , -90.0179462 , -89.96730399, -89.95807187,\n",
       "       -89.87673207, -89.97966728, -89.97541837, -89.91965177,\n",
       "       -89.90963765, -89.95740333, -90.02836119, -90.04058518,\n",
       "       -89.89787538, -89.89354894, -89.98241498, -89.94554998,\n",
       "       -89.93850808, -89.97668301, -89.92919725, -89.92254817,\n",
       "       -89.8317079 , -89.95047737, -89.91503645, -89.98944185,\n",
       "       -89.90231272, -89.95443721, -89.95224972, -89.94627922,\n",
       "       -89.92248585, -89.95479855, -89.89161547, -89.96472838,\n",
       "       -89.98930719, -89.95340912, -89.94632546, -89.96954215,\n",
       "       -89.92162669, -89.92757643, -89.97222556, -89.90040151,\n",
       "       -89.87810078, -89.93838127, -89.89206151, -89.88836143,\n",
       "       -89.94813579, -89.93620754, -89.88831142, -89.96294448,\n",
       "       -89.89851918, -89.91620396, -89.96882026, -89.93042325,\n",
       "       -89.87863356, -89.94361045, -89.9928768 , -90.00589908,\n",
       "       -89.9472595 , -89.98180339, -89.92842827, -89.98174911,\n",
       "       -90.02749975, -89.94333132, -89.98252147, -89.96795807,\n",
       "       -89.9436433 , -89.87310188, -89.88948063, -89.96824309,\n",
       "       -89.97737326, -89.91991512, -89.95502112, -89.87071592,\n",
       "       -89.99607017, -89.86748472, -89.83904405, -89.97262893,\n",
       "       -89.95416432, -89.91498272, -89.94504798, -89.94997751,\n",
       "       -89.94730758, -89.89986783, -89.97843884, -90.02727841,\n",
       "       -89.99267015, -89.8910564 , -90.02008395, -89.85432242,\n",
       "       -89.9303528 , -89.9848997 , -89.96972415, -89.94761412,\n",
       "       -89.95529327, -89.91370333, -89.94730295, -90.02392236,\n",
       "       -89.8775248 , -89.90460143, -89.89739305, -89.95853928,\n",
       "       -90.00180072, -89.89572624, -90.02234641, -89.98438709,\n",
       "       -89.92417808, -89.94076304, -89.89701848, -89.90195133,\n",
       "       -89.85396324, -89.97517724, -89.97092733, -89.90796252,\n",
       "       -89.89030197, -89.98149209, -90.01568089, -89.90315485,\n",
       "       -90.06358747, -89.90160609, -89.85787756, -89.98223552,\n",
       "       -89.89947907, -89.9012454 , -89.99553386, -90.02098797,\n",
       "       -89.9009333 , -89.94017376, -89.97941951, -89.96278326,\n",
       "       -89.84578525, -90.00782155, -89.94093418, -89.9507358 ,\n",
       "       -89.91487538, -89.87525364, -89.94435318, -89.91341722,\n",
       "       -89.929079  , -89.89084161, -89.92100336, -89.95249993,\n",
       "       -90.01285272, -90.00238004, -89.94798579, -89.94682273,\n",
       "       -89.94441901, -89.93256395, -89.94683292, -89.98729685,\n",
       "       -89.90421506, -89.90711241, -89.99944784, -89.86326676,\n",
       "       -89.90502881, -89.93619976, -89.9508163 , -89.91468954,\n",
       "       -89.89698279, -89.87933513, -89.98992689, -89.88951998,\n",
       "       -90.01385024, -89.95575853, -90.00247959, -89.93827186,\n",
       "       -89.89757359, -89.94251453, -89.89822636, -89.93126168,\n",
       "       -89.9809982 , -89.98456428, -89.86396855, -89.93001704,\n",
       "       -89.84813706, -89.99832755, -89.97404725, -89.97166086,\n",
       "       -89.95582851, -89.94064365, -89.92412698, -89.94526476,\n",
       "       -89.93281336, -89.88108306, -89.91698905, -89.97602981,\n",
       "       -89.94276888, -89.92048249, -89.90051741, -89.85309118,\n",
       "       -89.94859086, -89.95460962, -89.93348751, -89.86181533,\n",
       "       -89.95751485, -89.94733104, -89.89641259, -89.95081075,\n",
       "       -90.00154419, -89.91546969, -89.8691705 , -89.93408825,\n",
       "       -89.9392975 , -89.96961814, -89.88385904, -89.90981066,\n",
       "       -89.99610507, -89.94085326, -89.93369978, -89.94764645,\n",
       "       -89.97046765, -89.93659792, -89.91842077, -89.89566312,\n",
       "       -89.97226979, -90.06061142, -89.95504765, -89.92355889,\n",
       "       -89.92749649, -89.95376414, -89.94915807, -89.93429089,\n",
       "       -90.00771341, -89.92532128, -89.88777979, -89.92313368,\n",
       "       -89.99594434, -89.89623892, -89.95380086, -89.95989014,\n",
       "       -89.98347255, -89.96940302, -89.94708024, -89.97575496,\n",
       "       -89.93382169, -90.04349717, -89.97172686, -89.98069124,\n",
       "       -89.94720317, -89.93614885, -89.94794614, -89.95328523,\n",
       "       -89.89481752, -89.92606504, -89.90639479, -89.92885372,\n",
       "       -89.96007204, -89.92819839, -90.01620717, -89.90548022,\n",
       "       -89.93762917, -90.02693431, -89.99921622, -89.99525326,\n",
       "       -89.8847997 , -90.02578999, -89.87561424, -89.93703288,\n",
       "       -89.94167105, -89.96826779, -89.90591713, -90.03180275,\n",
       "       -89.90506084, -89.90169515, -89.95871185, -89.92876514,\n",
       "       -89.95493326, -89.96865406, -89.9934703 , -89.93169941,\n",
       "       -89.92767016, -90.0606583 , -89.93374011, -89.88976022,\n",
       "       -89.99915712, -89.99396901, -89.93826644, -89.90953936,\n",
       "       -89.91062911, -89.89665759, -90.0202094 , -89.96305145,\n",
       "       -89.91791729, -89.89805591, -89.94473032, -89.8944843 ,\n",
       "       -89.87790587, -89.85339927, -89.90809986, -90.0264314 ,\n",
       "       -89.94235875, -90.00029807, -90.02281903, -90.04793772,\n",
       "       -89.93394299, -89.91103234, -90.01840649, -89.92418383,\n",
       "       -89.89016453, -89.94875353, -89.92262798, -89.93381102,\n",
       "       -89.95434733, -89.96541667, -89.98476776, -89.9475751 ,\n",
       "       -89.86558769, -89.96665069, -89.95653164, -89.98466959,\n",
       "       -89.94380984, -89.94367422, -89.91851738, -89.88960546,\n",
       "       -89.90332112, -89.9185258 , -90.04393992, -89.94114077,\n",
       "       -89.92730763, -89.93952114, -90.00439528, -90.00109544,\n",
       "       -89.93376643, -89.92423699, -89.94032433, -89.93390364,\n",
       "       -89.90830794, -89.89516999, -89.93051661, -89.96092569,\n",
       "       -89.96230675, -90.00776316, -89.98776269, -89.95825495,\n",
       "       -89.90760533, -89.9343269 , -89.98769883, -89.86978525,\n",
       "       -89.92085545, -89.96923917, -89.84593954, -89.99092965,\n",
       "       -89.96365007, -89.90302575, -89.93175274, -89.93900557,\n",
       "       -89.86044595, -89.92629186, -89.92105716, -89.97909279,\n",
       "       -89.92973182, -89.9690061 , -89.92860801, -89.98242344,\n",
       "       -90.00118502, -89.95734523, -89.94472251, -89.97426312,\n",
       "       -89.98692603, -89.97278378, -89.9594362 , -89.95285093,\n",
       "       -90.00279949, -89.93215096, -89.89030074, -89.8917068 ,\n",
       "       -89.88311042, -89.98078333, -89.91792948, -90.00951851,\n",
       "       -89.99406898, -89.96497588, -90.02825809, -89.8780459 ,\n",
       "       -89.90403866, -89.97910956, -89.83342966, -89.96078437,\n",
       "       -89.998558  , -89.94808373, -90.00912579, -89.90579459,\n",
       "       -89.97234222, -89.92713306, -89.93336657, -89.97110613,\n",
       "       -89.98153001, -89.94184301, -89.95756663, -90.0146776 ,\n",
       "       -89.90980318, -89.91208811, -89.96595878, -90.04409252,\n",
       "       -89.92857538, -89.96477089, -89.96445424, -89.96974769,\n",
       "       -89.8656896 , -89.96446715, -89.90002747, -89.94335978,\n",
       "       -89.92943108, -89.94113332, -89.93214675, -89.94062704,\n",
       "       -89.96579271, -90.0392228 , -89.94232598, -89.9011992 ,\n",
       "       -89.94283949, -89.92037466, -89.92493749, -89.94791373,\n",
       "       -89.89549434, -89.86991148, -89.95237565, -89.94545864,\n",
       "       -89.92725517, -89.96990519, -89.89752346, -89.97155093,\n",
       "       -89.99635749, -89.92141985, -90.03813642, -89.98202938,\n",
       "       -89.9191832 , -89.94613516, -89.88560669, -89.93964636,\n",
       "       -89.97738518, -89.95547059, -89.87184207, -89.93765545,\n",
       "       -89.96792852, -90.05459326, -89.9812829 , -89.95626468,\n",
       "       -89.98646462, -89.98011835, -89.89100337, -89.9538809 ,\n",
       "       -89.90676434, -89.86483232, -89.99147552, -89.93630435,\n",
       "       -89.91089066, -89.95780076, -89.993756  , -89.9716376 ,\n",
       "       -89.89250049, -89.92519995, -89.91446319, -89.8805585 ,\n",
       "       -89.95325442, -89.97722895, -89.99882126, -89.875893  ,\n",
       "       -89.99302546, -89.9514974 , -89.92390944, -89.9528228 ,\n",
       "       -89.94455517, -89.98464909, -89.96493065, -90.01284168,\n",
       "       -90.00089511, -89.92805589, -89.99743412, -89.96910055,\n",
       "       -89.93882389, -90.00609254, -89.88396932, -89.99179932,\n",
       "       -89.95303779, -89.92330452, -89.97883477, -89.98061442,\n",
       "       -89.86069547, -90.01619624, -89.93309912, -89.90511084,\n",
       "       -89.93867492, -89.88321934, -89.92824435, -89.906631  ,\n",
       "       -89.92555782, -89.92747092, -89.97799484, -89.98191288,\n",
       "       -89.91711029, -90.03606968, -89.95426876, -89.92555564,\n",
       "       -89.93564233, -89.88158005, -89.98430532, -89.89824391,\n",
       "       -89.87397318, -89.93776231, -89.88813414, -89.95562313,\n",
       "       -89.98105136, -89.94706603, -89.99623141, -89.96121092,\n",
       "       -89.98417115, -89.92378325, -90.02568679, -89.98364201,\n",
       "       -89.96948273, -89.96282855, -89.91114193, -89.99007785,\n",
       "       -89.95400309, -90.01652784, -90.0204593 , -89.93104518,\n",
       "       -90.0189962 , -89.98047755, -90.00931777, -89.88198088,\n",
       "       -89.96011673, -90.00728097, -89.87584652, -89.97840163,\n",
       "       -89.95014306, -89.89663523, -89.93066923, -89.95694064,\n",
       "       -89.99088277, -89.92662917, -89.93688534, -89.96387682,\n",
       "       -89.92901637, -89.92823774, -89.88723937, -89.87964325,\n",
       "       -89.87836402, -90.00939316, -89.92249666, -89.89048829,\n",
       "       -90.01266263, -89.90743464, -89.99481653, -90.05198069,\n",
       "       -89.92853449, -89.97879367, -89.99523829, -89.95947119,\n",
       "       -89.9732624 , -89.93400556, -89.99758251, -89.96904977,\n",
       "       -89.95364793, -89.91188505, -90.03381421, -89.91244305,\n",
       "       -89.92537022, -89.98479288, -89.9145719 , -89.99739716,\n",
       "       -89.92735314, -90.00545884, -89.91592529, -89.84273471,\n",
       "       -89.95397814, -90.02123894, -89.96820054, -89.96210296,\n",
       "       -89.8457236 , -89.96747138, -89.96462655, -89.99504625,\n",
       "       -89.97712573, -90.05933656, -89.88619674, -89.9371573 ,\n",
       "       -89.87842147, -89.92944738, -89.97142673, -89.93954024,\n",
       "       -89.91649849, -90.00303796, -89.97924987, -89.94813283,\n",
       "       -89.92961917, -89.97098362, -90.02536521, -89.97478992,\n",
       "       -90.04600124, -89.92214001, -89.94589912, -90.06207386,\n",
       "       -89.97198249, -89.91961278, -89.94213263, -89.88177006,\n",
       "       -89.93445149, -89.98688577, -89.98044291, -89.92686849,\n",
       "       -89.98967439, -90.02385202, -89.98889431, -89.87096171,\n",
       "       -89.94249037, -89.98162252, -89.91814575, -89.88538149,\n",
       "       -89.98876403, -89.92370598, -90.00942811, -89.96495874,\n",
       "       -89.9380476 , -89.95923538, -89.94031659, -89.94369598,\n",
       "       -89.88311569, -89.94649329, -89.89695021, -89.95311838,\n",
       "       -90.0336069 , -89.95614931, -89.99213407, -89.86771269,\n",
       "       -89.94203183, -89.88880414, -89.91894654, -89.93969051,\n",
       "       -89.87674432, -89.97095069, -89.95011139, -89.92558474,\n",
       "       -90.02689201, -89.98260255, -90.04338276, -89.85836277,\n",
       "       -89.94372743, -89.96886425, -89.90152164, -89.93799161,\n",
       "       -89.93335185, -89.83649971, -89.94786586, -89.91578576,\n",
       "       -89.95719638, -89.94957648, -89.97703063, -89.96581659,\n",
       "       -89.96742084, -89.90794629, -89.90222239, -89.87200253,\n",
       "       -89.87763217, -89.97167811, -89.96704851, -89.92114802,\n",
       "       -90.01377213, -89.94776627, -89.92078073, -89.93924984,\n",
       "       -89.89327762, -89.90995757, -89.99980078, -89.8916413 ,\n",
       "       -89.87138413, -89.91718551, -89.96692183, -89.87896316,\n",
       "       -89.93156156, -89.9118727 , -89.9072204 , -89.93683571,\n",
       "       -89.88939692, -89.90677126, -89.86296552, -89.94445184,\n",
       "       -89.92353279, -89.91385444, -89.93484479, -89.89939975,\n",
       "       -89.93124876, -89.98371164, -89.90617377, -89.97686848,\n",
       "       -89.97929095, -89.94584045, -89.9700476 , -89.98276593,\n",
       "       -89.92177572, -89.92783252, -89.96615966, -89.87279471,\n",
       "       -89.92793407, -89.95756019, -89.89382455, -89.97332153,\n",
       "       -89.93924131, -89.94004142, -89.98359849, -89.96420871,\n",
       "       -89.93411249, -89.97754394, -90.00832741, -89.96138653,\n",
       "       -89.90116432, -89.91128236, -89.96836901, -90.04817481,\n",
       "       -89.90355545, -89.96365682, -89.9026594 , -89.9454669 ,\n",
       "       -89.92367404, -89.89783974, -89.95659599, -89.97119097,\n",
       "       -89.96386467, -89.96968514, -89.88625664, -89.96645752,\n",
       "       -89.90258283, -89.99841321, -89.94614667, -89.92199521,\n",
       "       -89.85836598, -89.98218853, -89.9484167 , -89.88683623,\n",
       "       -89.90049408, -89.94374506, -89.89927636, -89.97733401,\n",
       "       -89.96815405, -89.94807804, -90.00281634, -89.95468521,\n",
       "       -89.94472983, -89.93164112, -89.91993186, -89.99115921,\n",
       "       -89.99088035, -89.97350262, -89.9957699 , -89.95817092,\n",
       "       -89.94020736, -89.91962456, -89.92072831, -89.91218606,\n",
       "       -89.75737928, -89.93311496, -89.91707256, -89.99007588,\n",
       "       -89.97019839, -89.96160162, -89.93515555, -89.83821234,\n",
       "       -90.07174204, -89.95111679, -89.97010899, -89.94163593,\n",
       "       -89.9761224 , -89.94785043, -89.97586221, -89.88767047,\n",
       "       -89.88768527, -89.98353731, -89.93887874, -89.91145347,\n",
       "       -89.99705713, -89.88029671, -90.01158402, -89.95952077,\n",
       "       -90.01451871, -89.96062225, -89.9092634 , -90.00970649,\n",
       "       -89.95820288, -89.95400159, -89.96516812, -89.96483143,\n",
       "       -89.90799457, -89.9021064 , -89.93203987, -89.97119707,\n",
       "       -89.94975187, -89.96420358, -89.97252509, -89.8748004 ,\n",
       "       -90.04295542, -89.97621196, -89.88082624, -89.94465657,\n",
       "       -89.97209779, -89.96666645, -89.952112  , -89.96755554,\n",
       "       -89.95802648, -89.89412689, -89.93218048, -89.89411688,\n",
       "       -89.87461029, -89.8908596 , -90.02069625, -89.97525299,\n",
       "       -89.925399  , -89.94043414, -89.99657489, -89.88059745,\n",
       "       -89.99839969, -89.99877139, -89.87172769, -89.93916022,\n",
       "       -89.89760776, -89.95944667, -89.95574859, -89.90446969,\n",
       "       -89.96036088, -89.96814505, -89.95660234, -89.9587556 ,\n",
       "       -89.94662395, -89.99762785, -89.93475761, -89.87254356,\n",
       "       -89.98022123, -89.95357281, -89.9186859 , -89.95778839,\n",
       "       -89.92668045, -89.84907363, -90.01107472, -89.9330549 ,\n",
       "       -89.8643125 , -89.90326048, -89.95360376, -89.91311184,\n",
       "       -89.90086358, -89.96032506, -89.93511561, -89.95765294,\n",
       "       -89.91980324, -90.00763246, -89.95336462, -89.93863429,\n",
       "       -89.93194057, -89.84920342, -90.00058958, -90.00203776,\n",
       "       -89.8994064 , -89.97187611, -89.86779261, -89.98296334,\n",
       "       -89.99551473, -89.88471443, -90.03286501, -89.89417741,\n",
       "       -89.9267206 , -89.93722514, -89.97031619, -89.87906324,\n",
       "       -89.93987393, -89.92423484, -89.84620988, -90.0047109 ,\n",
       "       -89.96319002, -89.93469292, -89.90580362, -89.96067822,\n",
       "       -89.93688152, -90.02304323, -89.99219919, -89.85320792,\n",
       "       -89.91903409, -89.97046314, -90.00316999, -89.94652715,\n",
       "       -89.93418877, -89.89405825, -89.9893197 , -89.88131315,\n",
       "       -90.01205953, -89.93322676, -89.84819794, -89.94857167,\n",
       "       -89.95788946, -90.02042078, -89.96495617, -89.98847053,\n",
       "       -89.9133965 , -89.86812431, -89.90365877, -89.92440487,\n",
       "       -89.93750521, -89.90756944, -89.93995123, -89.90106348,\n",
       "       -89.94453169, -89.97289275, -89.93713959, -89.96513922,\n",
       "       -89.94672291, -89.96921233, -89.99003453, -89.94286281,\n",
       "       -89.95253295, -89.9833359 , -89.95098095, -89.93126579,\n",
       "       -89.88038746, -89.97923434, -89.88321279, -89.95897309,\n",
       "       -89.90318706, -89.9602414 , -89.85427004, -89.93522972,\n",
       "       -89.99475352, -89.87608887, -89.96023063, -89.898597  ,\n",
       "       -89.91833269, -89.92828235, -89.91546483, -90.00605135,\n",
       "       -90.00084383, -89.95459586, -89.95899889, -89.9589061 ])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est.effect(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kvsZS91J73op"
   },
   "source": [
    "### Prédictions \"Paradis\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calcul MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(y,y_pred):\n",
    "    return 1/2*(y-y_pred)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calcul de l'ATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "Xvmi5lnT72Ax"
   },
   "outputs": [],
   "source": [
    "def ATE_paradis(beta, bias, f=lambda i:i, g=lambda i:i):\n",
    "    p=beta.shape[1]\n",
    "    if p==1:\n",
    "        ate = integrate.quad(lambda x: (g(beta[1]*x + bias[1]) -f(beta[0]*x + bias[0]))*sp.stats.norm.pdf(x,0,1),-1000 , 1000)\n",
    "    if p==2:\n",
    "        ate=integrate.dblquad(lambda x, y: (g(beta[1,0]*x + beta[1,1]*y + bias[1]) -f(beta[0,0]*x + beta[0,1]*y + bias[0])\n",
    "                                           )*sp.stats.norm.pdf(x,0,1)*sp.stats.norm.pdf(y,0,1),-1000 , 1000, lambda y :-1000,lambda y : 1000)\n",
    "    if p>2:\n",
    "        raise Warning('dimension above 2')\n",
    "    return  ate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "vVGjotUsw566"
   },
   "outputs": [],
   "source": [
    "def monte_carlo(Nobs, dim, beta, bias, f, g, W):\n",
    "    '''\n",
    "    Input :\n",
    "    \n",
    "    Nobs : Nombre de lignes da la matrice X i.e. nombre de personnes.\n",
    "    dim : Nombre de colonnes de la matrice X i.e. nombres de caractéristiques (features).\n",
    "    beta : Vecteur de dimension (2, dim), note dim doit être < 10\n",
    "    bias : Vecteur de dimension (1, 2).\n",
    "    W : Vecteur de dimension (1, Nobs) contenant des 0 ou 1 pour désigner l'affectation du traitement.\n",
    "    f et g sont des fonctions.\n",
    "    \n",
    "    Output:\n",
    "    \n",
    "    ATE : ATE calculé par la méthode de Monte Carlo\n",
    "    '''\n",
    "    moy = np.zeros(dim)\n",
    "    var = np.eye(dim)\n",
    "    X = np.random.multivariate_normal(moy, var, Nobs)\n",
    "    ATE = np.mean(g(X.dot(beta[1])+ bias[1]) - f(X.dot(beta[0])+ bias[0])) \n",
    "            \n",
    "    return ATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WZHKy9grdYdl",
    "outputId": "7115bae0-072e-4393-b3aa-d6a2f6b344ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE calculé par intégration: (-89.99999999995957, 8.239932487719148e-08)\n",
      "ATE calculé par Monte Carlo: -84.72884244179949\n"
     ]
    }
   ],
   "source": [
    "print('ATE calculé par intégration: {}'.format(ATE_paradis(beta, bias, f=f, g=g)))\n",
    "print('ATE calculé par Monte Carlo: {}'.format(monte_carlo(10**6, d, beta, bias, f, g, W)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "TDSQDcFgwgeS",
    "outputId": "f41a3245-5639-426a-fbea-9930a90836c8",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = []\n",
    "#1- varier Nobs pour ate_hat_S et le comparer avec mc_est (meth. monte carlo) avec 10**8\n",
    "#2 - ajouter une courbe avec l'estimation avec causalml avec la borne inf et max et ate_hat_S\n",
    "for i in range(2,8):\n",
    "    mc_est = monte_carlo(10**i, d, beta, bias, f, g, W)\n",
    "    res.append([abs(mc_est - ate_hat_S)])\n",
    "plt.figure()\n",
    "plt.title('Evolution de l\\'estimation de l\\'ATE par Monte Carlo en fonction du nombre d\\'observations')\n",
    "plt.plot(res);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calcul des Intervalles de Confiance de l'ATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def causal_generation_bootstrap(beta, bias, B= 999, Nobs =1000, dim=2, f=lambda i:i, g=lambda i:i, p=None):\n",
    "    '''\n",
    "    Create list of bootstrap elements\n",
    "    Input :\n",
    "    \n",
    "    B : Nombre d'échantillons Boostrap, 999 est une valeur par défaut pertinente\n",
    "    Nobs : Nombre de lignes da la matrice X i.e. nombre de personnes, 1000 par défaut\n",
    "    dim : Nombre de colonnes de la matrice X i.e. nombres de caractéristiques \n",
    "    (features), 2 par défaut\n",
    "    beta : Vecteur de dimension (2, dim).\n",
    "    bias : Vecteur de dimension (1, 2).\n",
    "    W : Vecteur de dimension (1, Nobs) contenant des 0 ou 1 pour désigner \n",
    "    l'affectation du traitement.\n",
    "    f et g sont des fonctions, identité par défaut\n",
    "    \n",
    "    Output:\n",
    "    \n",
    "    [(X, W, Y)] : liste de B Triplets contenant la matrice X des features, W \n",
    "    le vecteur de l'affectation du traitement et Y le vecteur des résultats \n",
    "    potentiels. \n",
    "                \n",
    "    '''\n",
    "    Bootstraps=[]\n",
    "\n",
    "    for b in range(B):\n",
    "        Bootstraps.append(causal_generation(Nobs, dim, beta, bias, f, g, p))\n",
    "      \n",
    "    return Bootstraps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IC(Bootstraps, base_metalearner=SLearner(),alpha=0.05):\n",
    "    \n",
    "    '''\n",
    "    Calculate l'intervalle de confiance d'un métalearner\n",
    "    \n",
    "    Input :\n",
    "    \n",
    "    Bootstraps : Liste d'échantillons Boostraps comprenant B triplets (X,Y,W)\n",
    "    base_metalerner : metalearner à évaluer\n",
    "    \n",
    "    Output:\n",
    "    \n",
    "    IC : (IC inf , IC sup) du métalearner \n",
    "    '''\n",
    "    #import\n",
    "    from scipy.stats import norm\n",
    "    \n",
    "    #Calcul de l'ATE les B estimateurs du Bootstrap\n",
    "    ATEs=np.zeros((len(Bootstraps)))\n",
    "\n",
    "    for i in range(len(Bootstraps)):\n",
    "        base_metalearner.fit(Bootstraps[i][0],Bootstraps[i][1],Bootstraps[i][2])\n",
    "        \n",
    "        if type(base_metalearner) is XLearner:\n",
    "            propensity=propensity_score(Bootstraps[i][0], Bootstraps[i][1])\n",
    "            base_metalearner.predict_CATE(Bootstraps[i][0], propensity)\n",
    "        else:\n",
    "            base_metalearner.predict_CATE(Bootstraps[i][0])\n",
    "        ATEs[i]=base_metalearner.predict_ATE()\n",
    "    \n",
    "    #Calcul des intervalles de confiance\n",
    "    Mu_ATEs= ATEs.mean()\n",
    "    std_ATEs= ATEs.std()\n",
    "    ATEs_tilt= (ATEs-Mu_ATEs)/std_ATEs\n",
    "    ATEs_tilt.sort()\n",
    "    ATEs.sort()\n",
    "    IC_inf, IC_sup = ATEs[int(B*(alpha/(2)))], ATEs[int(B*(1-alpha/(2)))]\n",
    "    \n",
    "    return (Mu_ATEs, IC_inf, IC_sup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-94.11134098860593, -372.3859819127638, 204.34128775836865)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B=999\n",
    "Bootstraps=causal_generation_bootstrap(beta, bias, B= B, Nobs =N, dim=d, f=f, g=g, p=p)\n",
    "IC(Bootstraps, base_metalearner=SLearner(),alpha=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-80.33528788218973, -384.3907603787811, 218.68187473543023)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B=999\n",
    "Bootstraps=causal_generation_bootstrap(beta, bias, B= B, Nobs =N, dim=d, f=f, g=g, p=p)\n",
    "IC(Bootstraps, base_metalearner=TLearner(),alpha=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-81.0747113569056, -359.57592471773114, 212.8489933767927)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B=999\n",
    "Bootstraps=causal_generation_bootstrap(beta, bias, B= B, Nobs =N, dim=d, f=f, g=g, p=p)\n",
    "IC(Bootstraps, base_metalearner=XLearner(),alpha=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-59.971538415585755, -249.55493540957792, 52.65154474345414)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B=5\n",
    "Bootstraps=causal_generation_bootstrap(beta, bias, B= B, Nobs =N, dim=d, f=f, g=g, p=p)\n",
    "IC(Bootstraps, base_metalearner=DRLearner(),alpha=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparaison graphiques des résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graphic_comparison(nb_obs, d, p, beta, bias, f, g, B, base_learner_homemade, base_learner_causalml):\n",
    "\n",
    "  '''\n",
    "  Create a graphic to compare our bases learners vs base learners from causalml \n",
    "\n",
    "  Input :\n",
    "    \n",
    "  B : Nombre d'échantillons Boostrap, 999 est une valeur par défaut pertinente\n",
    "  nb_obs : Nombre de lignes da la matrice X, les listes sont acceptables i.e. nombre de personnes, 1000 par défaut\n",
    "  dim : Nombre de colonnes de la matrice X i.e. nombres de caractéristiques (features), 2 par défaut\n",
    "  beta : Vecteur de dimension (2, dim).\n",
    "  bias : Vecteur de dimension (1, 2).\n",
    "  W : Vecteur de dimension (1, Nobs) contenant des 0 ou 1 pour désigner l'affectation du traitement.\n",
    "  f et g sont des fonctions, identité par défaut\n",
    "    \n",
    "  Output:\n",
    "  Graphique comparant nos base_learner avec ceux du causal_ml\n",
    "  '''\n",
    "\n",
    "  ate_causal_ml = []\n",
    "  lb_causal_ml = []\n",
    "  ub_causal_ml = []\n",
    "\n",
    "  ates = []\n",
    "  ates_inf = []\n",
    "  ates_sup = []\n",
    "\n",
    "  for n in nb_obs:\n",
    "\n",
    "    # Génération des données\n",
    "    Bootstraps=causal_generation_bootstrap(beta, bias, B= B, Nobs =n, dim=d, f=f, g=g, p=p) \n",
    "    mu, inf, sup = IC(Bootstraps, base_metalearner=base_learner_homemade, alpha=0.05)\n",
    "    ates.append(mu)\n",
    "    ates_inf.append(inf)\n",
    "    ates_sup.append(sup)\n",
    "\n",
    "    # S learner causal ML\n",
    "    X, W, Y = causal_generation(n, d, beta, bias, f, g, p)\n",
    "    lr = base_learner_causalml\n",
    "    te, lb, ub = lr.estimate_ate(X, W, Y)\n",
    "    ate_causal_ml.append(te[0])\n",
    "    lb_causal_ml.append(lb[0])\n",
    "    ub_causal_ml.append(ub[0])\n",
    "\n",
    "\n",
    "  plt.plot(nb_obs,ates, color='blue',label = 'ATE_homemade')\n",
    "  plt.fill_between(nb_obs, ates_inf,ates_sup,alpha = 0.5, color='blue', label = 'IC_ATE_homemade')\n",
    "  plt.plot(nb_obs, ate_causal_ml,color='orange',label='ATE_causal_ml')\n",
    "  plt.fill_between(nb_obs, lb_causal_ml, ub_causal_ml,alpha = 0.5, color='orange',label='IC_ATE_causalml')\n",
    "  plt.legend()\n",
    "  plt.show()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nb_obs = [i for i in range(100,1000,100)]\n",
    "plt.title('Comparaison des Slearners');\n",
    "graphic_comparison(nb_obs, d, p, beta, bias, f, g, B, SLearner(), LRSRegressor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_obs = [i for i in range(100,1000,100)]\n",
    "plt.title('Comparaison des Tlearners');\n",
    "graphic_comparison(nb_obs, d, p, beta, bias, f, g, B, TLearner(), XGBTRegressor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test sur clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import tp_knn_source\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paramètres pour faciliter le calcul de l'ATE par intégration\n",
    "N = 500\n",
    "d = 2                                     # d = 2, afin de pouvoir être calculé par intégration et avec Monte Carlo\n",
    "p = 0.8\n",
    "beta0 = np.random.uniform(1, 30, (1, d))\n",
    "beta1 = np.random.uniform(1, 100, (1, d))\n",
    "beta = np.vstack((beta0,beta0))               # beta0 = beta1           \n",
    "bias = np.array([0,10])                       # Gamma0 = Gamma1 \n",
    "f = lambda x:x\n",
    "g = lambda x:x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "def causal_generation_bigauss(Nobs, dim, beta, bias, f, g, p):\n",
    "    '''\n",
    "    Input :\n",
    "    \n",
    "    Nobs : Nombre de lignes da la matrice X i.e. nombre de personnes.\n",
    "    dim : Nombre de colonnes de la matrice X i.e. nombres de caractéristiques (features).\n",
    "    beta : Vecteur de dimension (2, dim).\n",
    "    bias : Vecteur de dimension (1, 2).\n",
    "    W : Vecteur de dimension (1, Nobs) contenant des 0 ou 1 pour désigner \n",
    "    l'affectation du traitement.\n",
    "    f et g sont des fonctions.\n",
    "    \n",
    "    Output:\n",
    "    \n",
    "    (X, Y, W) : Triplet contenant la matrice X des features, Y le vecteur des \n",
    "                résultats potentiels et W le vecteur de l'affectation du traitement.\n",
    "    '''\n",
    "    moy = np.zeros(dim)\n",
    "    var = np.eye(dim)\n",
    "    n1 = int(Nobs/2)\n",
    "    n2 = Nobs-n1\n",
    "    X, _= tp_knn_source.rand_bi_gauss(n1=n1, n2=n2, mu1=[1, 1], mu2=[0.5, 0.5], sigmas1=[0.5, 0.1],\n",
    "                  sigmas2=[0.1, 0.1])\n",
    "    \n",
    "    Y = np.zeros(Nobs)\n",
    "\n",
    "    W = treatment_assign(Nobs, dim, X, p)\n",
    "\n",
    "    for i in range(Nobs):\n",
    "        bruit = np.random.normal(0, 1)\n",
    "        if W[i] == 0:\n",
    "            Y[i] = f(beta[0] @ X[i] + bias[0]) + bruit\n",
    "        if W[i] == 1:\n",
    "            Y[i] = g(beta[1] @ X[i] + bias[1]) + bruit\n",
    "            \n",
    "    return (X, W, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Génération des données\n",
    "X, W, Y = causal_generation_bigauss(N, d, beta, bias, f, g, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering sur les features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gmm = GaussianMixture(n_components=2)\n",
    "gmm.fit(X)\n",
    "groups=gmm.predict(X)\n",
    "#Plot\n",
    "data=[X, groups]\n",
    "tp_knn_source.plot_2d(data[0],data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering_features(X, W, Y, n_components = 2 ,cluster_model = 'gaussian', \n",
    "                        base_metalearner=SLearner(base_estimator=LinearRegression())):\n",
    "    \n",
    "    #Clusters identification\n",
    "    if cluster_model == 'gaussian':\n",
    "        clf = GaussianMixture(n_components=n_components)\n",
    "    else:\n",
    "        clf = KMeans(n_clusters=n_components)\n",
    "    clf.fit(X)\n",
    "    groups=clf.predict(X)\n",
    "    labels=np.unique(groups)\n",
    "    \n",
    "    #CATE et ATE Calculation per cluster\n",
    "    ates={}\n",
    "    base_metalearner.fit(X,W,Y)\n",
    "        \n",
    "    if type(base_metalearner) is XLearner:\n",
    "        propensity=propensity_score(X, W)\n",
    "        cate_hat = base_metalearner.predict_CATE(X, propensity)\n",
    "    else:\n",
    "        cate_hat = base_metalearner.predict_CATE(X)\n",
    "    print(\"- Les dimensions du CATE pour le groupe complet sont de {}.\".format(cate_hat.shape))    \n",
    "    \n",
    "    ate_hat = base_metalearner.predict_ATE()\n",
    "    print(\"- L'estimation de la valeur de l'ATE pour le groupe complet = {}.\".format(ate_hat))\n",
    "    \n",
    "    for label in labels:\n",
    "        idx_group=groups==label             \n",
    "        print(\"- Les dimensions du CATE pour le groupe {} sont de {}.\".format(label,cate_hat[idx_group].shape))\n",
    "        ate_hat =cate_hat[idx_group].mean()\n",
    "        print(\"- L'estimation de la valeur de l'ATE pour le groupe {} = {}.\".format(label, ate_hat))\n",
    "        ates[label] = ate_hat\n",
    "    return ates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Les dimensions du CATE pour le groupe complet sont de (500,).\n",
      "- L'estimation de la valeur de l'ATE pour le groupe complet = 10.021844075611257.\n",
      "- Les dimensions du CATE pour le groupe 0 sont de (106,).\n",
      "- L'estimation de la valeur de l'ATE pour le groupe 0 = 10.07673525937487.\n",
      "- Les dimensions du CATE pour le groupe 1 sont de (145,).\n",
      "- L'estimation de la valeur de l'ATE pour le groupe 1 = 9.963802537005085.\n",
      "- Les dimensions du CATE pour le groupe 2 sont de (249,).\n",
      "- L'estimation de la valeur de l'ATE pour le groupe 2 = 10.032276033920306.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 10.07673525937487, 1: 9.963802537005085, 2: 10.032276033920306}"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustering_features(X, W, Y, n_components = 3 ,cluster_model = 'gaussian', \n",
    "                        base_metalearner=XLearner())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering sur le CATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering_cate(X, W, Y, n_components = 2 ,cluster_model = 'gaussian', \n",
    "                        base_metalearner=SLearner(base_estimator=LinearRegression())):\n",
    "    \n",
    "    #CATE Calculation\n",
    "    ates={}\n",
    "    base_metalearner.fit(X,W,Y)\n",
    "    \n",
    "    if type(base_metalearner) is XLearner:\n",
    "        propensity=propensity_score(X, W)\n",
    "        cate_hat = base_metalearner.predict_CATE(X, propensity)\n",
    "    else:\n",
    "        cate_hat = base_metalearner.predict_CATE(X)\n",
    "       \n",
    "    print(\"- Les dimensions du CATE pour le groupe complet sont de {}.\".format(cate_hat.shape))\n",
    "    ate_hat = base_metalearner.predict_ATE()\n",
    "    print(\"- L'estimation de la valeur de l'ATE pour le groupe complet = {}.\".format(cate_hat.mean()))\n",
    "    \n",
    "    #Clusters identification\n",
    "    CATE=cate_hat.reshape(-1, 1)\n",
    "    if cluster_model == 'gaussian':\n",
    "        clf = GaussianMixture(n_components=n_components)\n",
    "    else:\n",
    "        clf = KMeans(n_clusters=n_components)\n",
    "    clf.fit(CATE)\n",
    "    groups=clf.predict(CATE)\n",
    "    labels=np.unique(groups)\n",
    "    \n",
    "    #CATE et ATE Calculation per cluster\n",
    "    ates={}\n",
    "    for label in labels:\n",
    "        idx_group=groups==label             \n",
    "        print(\"- Les dimensions du CATE pour le groupe {} sont de {}.\".format(label,cate_hat[idx_group].shape))\n",
    "        ate_hat =cate_hat[idx_group].mean()\n",
    "        print(\"- L'estimation de la valeur de l'ATE pour le groupe {} = {}.\".format(label, ate_hat))\n",
    "        ates[label] = ate_hat\n",
    "    \n",
    "    return ates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Les dimensions du CATE pour le groupe complet sont de (500,).\n",
      "- L'estimation de la valeur de l'ATE pour le groupe complet = 9.869277011833885.\n",
      "- Les dimensions du CATE pour le groupe 0 sont de (46,).\n",
      "- L'estimation de la valeur de l'ATE pour le groupe 0 = 8.043004680671421.\n",
      "- Les dimensions du CATE pour le groupe 1 sont de (177,).\n",
      "- L'estimation de la valeur de l'ATE pour le groupe 1 = 10.905890792742209.\n",
      "- Les dimensions du CATE pour le groupe 2 sont de (277,).\n",
      "- L'estimation de la valeur de l'ATE pour le groupe 2 = 9.510171914406813.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 8.043004680671421, 1: 10.905890792742209, 2: 9.510171914406813}"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustering_cate(X, W, Y, n_components = 3 ,cluster_model = 'gaussian', \n",
    "                        base_metalearner=SLearner(base_estimator=RandomForestRegressor()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering Hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering_hybrid(X, W, Y, n_components = 2 ,cluster_model = 'gaussian', \n",
    "                        base_metalearner=SLearner(base_estimator=LinearRegression())):\n",
    "    \n",
    "    #CATE Calculation\n",
    "    ates={}\n",
    "    base_metalearner.fit(X,W,Y)\n",
    "\n",
    "    if type(base_metalearner) is XLearner:\n",
    "        propensity=propensity_score(X, W)\n",
    "        cate_hat = base_metalearner.predict_CATE(X, propensity)\n",
    "    else:\n",
    "        cate_hat = base_metalearner.predict_CATE(X)\n",
    "\n",
    "    print(\"- Les dimensions du CATE pour le groupe complet sont de {}.\".format(cate_hat.shape))\n",
    "    ate_hat = base_metalearner.predict_ATE()\n",
    "    print(\"- L'estimation de la valeur de l'ATE pour le groupe complet = {}.\".format(cate_hat.mean()))\n",
    "\n",
    "    #hybrid features calculation\n",
    "    CATE=cate_hat.reshape(-1, 1)\n",
    "    features = np.hstack((X,CATE))\n",
    "\n",
    "    #Clusters identification\n",
    "    if cluster_model == 'gaussian':\n",
    "        clf = GaussianMixture(n_components=n_components)\n",
    "    else:\n",
    "        clf = KMeans(n_clusters=n_components)\n",
    "    clf.fit(features)\n",
    "    groups=clf.predict(features)\n",
    "    labels=np.unique(groups)\n",
    "    \n",
    "    #cluster calculation (might be wrong)\n",
    "    for label in labels:\n",
    "        idx_group=groups==label             \n",
    "        print(\"- Les dimensions du CATE pour le groupe {} sont de {}.\".format(label,cate_hat[idx_group].shape))\n",
    "        ate_hat =cate_hat[idx_group].mean()\n",
    "        print(\"- L'estimation de la valeur de l'ATE pour le groupe {} = {}.\".format(label, ate_hat))\n",
    "        ates[label] = ate_hat\n",
    "    \n",
    "    return ates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Les dimensions du CATE pour le groupe complet sont de (500,).\n",
      "- L'estimation de la valeur de l'ATE pour le groupe complet = 9.86483482279023.\n",
      "- Les dimensions du CATE pour le groupe 0 sont de (250,).\n",
      "- L'estimation de la valeur de l'ATE pour le groupe 0 = 9.688930496639864.\n",
      "- Les dimensions du CATE pour le groupe 1 sont de (250,).\n",
      "- L'estimation de la valeur de l'ATE pour le groupe 1 = 10.040739148940597.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 9.688930496639864, 1: 10.040739148940597}"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustering_hybrid(X, W, Y, n_components = 2 ,cluster_model = 'gaussian', \n",
    "                        base_metalearner=SLearner(base_estimator=RandomForestRegressor()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generic clustering function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fonction clustering qui calcule aussi le cate et l'ate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering_ext(X, W, Y, n_components = 2 , approach ='hybrid', cluster_model = 'gaussian', \n",
    "                        base_metalearner=SLearner(base_estimator=LinearRegression()),verbose=False):\n",
    "    \"\"\"Clustering function\n",
    "    The function shall be fed with X, W and Y and will calculate .\n",
    "    -cluster models available are : 'gaussian' for GMM and KNN for None or others,\n",
    "    -Clustering approaches avalable are 'features', 'cate' and 'hybrid' for (cate + hybrid)\n",
    "    returns dictionnaries of ates, cates \"\"\"\n",
    "    \n",
    "    #CATE et ATE calculation per cluster\n",
    "    ates={}\n",
    "    cates={}\n",
    "    base_metalearner.fit(X,W,Y)\n",
    "        \n",
    "    if type(base_metalearner) is XLearner:\n",
    "        propensity=propensity_score(X, W)\n",
    "        cate_hat = base_metalearner.predict_CATE(X, propensity)\n",
    "    else:\n",
    "        cate_hat = base_metalearner.predict_CATE(X)\n",
    "    if verbose ==True:    \n",
    "        print(\"- Les dimensions du CATE pour le groupe complet sont de {}.\".format(cate_hat.shape))    \n",
    "    \n",
    "    ate_hat = base_metalearner.predict_ATE()\n",
    "    if verbose ==True:\n",
    "        print(\"- L'estimation de la valeur de l'ATE pour le groupe complet = {}.\".format(ate_hat))\n",
    "    \n",
    "    #features calculation\n",
    "    assert (approach=='hybrid' or \n",
    "            approach=='cate' or \n",
    "            approach=='features' ), \"clustering method choosen differs from 'hybrid' or 'cate' or 'features'\"\n",
    "    if approach=='hybrid':\n",
    "        features = np.hstack((X,cate_hat.reshape(-1, 1)))\n",
    "    if approach=='cate':\n",
    "        features=cate_hat.reshape(-1, 1)\n",
    "    if approach=='features':\n",
    "        features=X\n",
    "    \n",
    "    #Clusters identification\n",
    "    if cluster_model == 'gaussian':\n",
    "        clf = GaussianMixture(n_components=n_components)\n",
    "    else:\n",
    "        clf = KMeans(n_clusters=n_components)\n",
    "    clf.fit(features)\n",
    "    groups=clf.predict(features)\n",
    "    labels=np.unique(groups)\n",
    "    \n",
    "    #CATEs et ATEs calculations per cluster\n",
    "    for label in labels:\n",
    "        idx_group=groups==label             \n",
    "        if verbose ==True:\n",
    "            print(\"- Les dimensions du CATE pour le groupe {} sont de {}.\".format(label,cate_hat[idx_group].shape))\n",
    "        cates[label] = cate_hat[idx_group]\n",
    "        ate_hat =cate_hat[idx_group].mean()\n",
    "        if verbose ==True:\n",
    "            print(\"- L'estimation de la valeur de l'ATE pour le groupe {} = {}.\".format(label, ate_hat))\n",
    "        ates[label] = ate_hat\n",
    "    return ates, cates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Les dimensions du CATE pour le groupe complet sont de (500,).\n",
      "- L'estimation de la valeur de l'ATE pour le groupe complet = 9.847876264891017.\n",
      "- Les dimensions du CATE pour le groupe 0 sont de (252,).\n",
      "- L'estimation de la valeur de l'ATE pour le groupe 0 = 9.076183682050779.\n",
      "- Les dimensions du CATE pour le groupe 1 sont de (248,).\n",
      "- L'estimation de la valeur de l'ATE pour le groupe 1 = 10.632015502293196.\n"
     ]
    }
   ],
   "source": [
    "ate, cates = clustering_ext(X, W, Y, n_components = 2 ,approach='cate',cluster_model = 'knn', \n",
    "                        base_metalearner=SLearner(base_estimator=RandomForestRegressor()),verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fonction clustering simple qui prend en entrée le cate et l'ate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering(X, cate, ate, n_components = 2 , approach ='hybrid', cluster_model = 'gaussian', verbose=False):\n",
    "    \"\"\"Simplified clustering function. \n",
    "    The function shall be fed with X, cate and ate as it is not calculated into the function.\n",
    "    -cluster models available are : 'gaussian' for GMM and KNN for None or others,\n",
    "    -Clustering approaches avalable are 'features', 'cate' and 'hybrid' for (cate + hybrid)\n",
    "    returns dictionnaries of ates, cates \"\"\"\n",
    "    \n",
    "    assert X.shape[0]==cate.shape[0], 'dim of cate and X not compatible'\n",
    "    assert isinstance(cate,np.ndarray), 'dim of cate and X not compatible'\n",
    "    \n",
    "    #CATE et ATE calculation per cluster\n",
    "    ates={}\n",
    "    cates={}\n",
    "\n",
    "    if verbose ==True:    \n",
    "        print(\"- Les dimensions du CATE pour le groupe complet sont de {}.\".format(cate.shape))    \n",
    "    if verbose ==True:\n",
    "        print(\"- L'estimation de la valeur de l'ATE pour le groupe complet = {}.\".format(ate))\n",
    "    \n",
    "    #features calculation\n",
    "    assert (approach=='hybrid' or \n",
    "            approach=='cate' or \n",
    "            approach=='features' ), \"clustering method choosen differs from 'hybrid' or 'cate' or 'features'\"\n",
    "    if approach=='hybrid':\n",
    "        features = np.hstack((X,cate.reshape(-1, 1)))\n",
    "    if approach=='cate':\n",
    "        features=cate.reshape(-1, 1)\n",
    "    if approach=='features':\n",
    "        features=X\n",
    "    \n",
    "    #Clusters identification\n",
    "    if cluster_model == 'gaussian':\n",
    "        clf = GaussianMixture(n_components=n_components)\n",
    "    else:\n",
    "        clf = KMeans(n_clusters=n_components)\n",
    "    clf.fit(features)\n",
    "    groups=clf.predict(features)\n",
    "    labels=np.unique(groups)\n",
    "    \n",
    "    #CATEs et ATEs calculations per cluster\n",
    "    for label in labels:\n",
    "        idx_group=groups==label             \n",
    "        if verbose ==True:\n",
    "            print(\"- Les dimensions du CATE pour le groupe {} sont de {}.\".format(label,cate[idx_group].shape))\n",
    "        cates[label] = cate[idx_group]\n",
    "        ate_hat =cate[idx_group].mean()\n",
    "        if verbose ==True:\n",
    "            print(\"- L'estimation de la valeur de l'ATE pour le groupe {} = {}.\".format(label, ate_hat))\n",
    "        ates[label] = ate_hat\n",
    "    return ates, cates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((500, 2), (500,), (500,))"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, W.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Les dimensions du CATE pour le groupe complet sont de (500,).\n",
      "- L'estimation de la valeur de l'ATE pour le groupe complet = 9.875267372010464.\n",
      "- Les dimensions du CATE pour le groupe 0 sont de (262,).\n",
      "- L'estimation de la valeur de l'ATE pour le groupe 0 = 10.614331801036785.\n",
      "- Les dimensions du CATE pour le groupe 1 sont de (238,).\n",
      "- L'estimation de la valeur de l'ATE pour le groupe 1 = 9.061675437536113.\n"
     ]
    }
   ],
   "source": [
    "slearner=SLearner(base_estimator=RandomForestRegressor())\n",
    "slearner.fit(X,W,Y)\n",
    "ate, cates = clustering(X, slearner.predict_CATE(X), slearner.predict_ATE(), \n",
    "                            n_components = 2 ,approach='cate',cluster_model = 'knn',verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improved Metalearners (drafts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from base import is_classifier, clone\n",
    "from sklearn.utils import indexable, check_random_state, _safe_indexing\n",
    "from sklearn.utils.validation import _check_fit_params\n",
    "from sklearn.utils.validation import _num_samples\n",
    "from sklearn.utils.validation import _deprecate_positional_args\n",
    "from sklearn.utils.fixes import delayed\n",
    "from sklearn.utils.metaestimators import _safe_split\n",
    "from sklearn.metrics import check_scoring\n",
    "from sklearn.metrics._scorer import _check_multimetric_scoring, _MultimetricScorer\n",
    "from sklearn.exceptions import FitFailedWarning, NotFittedError\n",
    "from sklearn.model_selection import check_cv\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.base import is_classifier, clone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iSlearner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "class iSLearner(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"\n",
    "    Homemade SLearner class with clustering capabilities\n",
    "    -cluster models available are : 'gaussian' for GMM and kmeans for None or others,\n",
    "    -clustering approaches available are 'features', 'cate' and 'hybrid' for (cate + hybrid)\n",
    "    -cv in option\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, base_estimator=LinearRegression()):\n",
    "        self.estimator = base_estimator\n",
    "        \n",
    "    def fit(self, X, W, Y, cv = None):\n",
    "        self.X = X\n",
    "        self.W = W\n",
    "        self.Y = Y\n",
    "        self.cv = cv\n",
    "                \n",
    "        if self.cv==None:\n",
    "            self.features = np.hstack((self.X, self.W[:,np.newaxis]))\n",
    "            self.clf = self.estimator.fit(self.features, self.Y)\n",
    "        else:\n",
    "            assert isinstance(self.cv, int),'cv must be an integer'\n",
    "            self.kf = KFold(n_splits=self.cv, shuffle=False)\n",
    "            self.splits = list(self.kf.split(self.X,self.W,self.Y))\n",
    "            self.clfs = []\n",
    "            for train, _ in self.splits:\n",
    "                X_train = self.X[train]\n",
    "                Y_train = self.Y[train]\n",
    "                W_train = self.W[train]\n",
    "                features = np.hstack((X_train, W_train[:,np.newaxis]))\n",
    "                self.clfs.append(clone(self.estimator).fit(features, Y_train))\n",
    "    \n",
    "    def clustering_function(self):\n",
    "        \"\"\"\n",
    "        Clustering function\n",
    "        INPUTS:\n",
    "        see function predict_CATE\n",
    "        OUTPUTS:\n",
    "        returns dictionnaries of ates, cates \n",
    "        \"\"\"\n",
    "\n",
    "        #CATE et ATE calculation\n",
    "        cate_hat = self.Y_1_hat - self.Y_0_hat\n",
    "        if self.verbose ==True:    \n",
    "            print(\"- Les dimensions du CATE pour le groupe complet sont de {}.\".format(cate_hat.shape))    \n",
    "        if self.verbose ==True:\n",
    "            print(\"- L'estimation de la valeur de l'ATE pour le groupe complet = {}.\".format(cate_hat.mean()))\n",
    "\n",
    "        #features calculation\n",
    "        assert (self.approach=='hybrid' or \n",
    "                self.approach=='cate' or \n",
    "                self.approach=='features'), \"clustering method choosen differs from 'hybrid' or 'cate' or 'features'\"\n",
    "        if self.approach=='hybrid':\n",
    "            features = np.hstack((self.X,cate_hat.reshape(-1, 1)))\n",
    "        if self.approach=='cate':\n",
    "            features=cate_hat.reshape(-1, 1)\n",
    "        if self.approach=='features':\n",
    "            features=self.X\n",
    "\n",
    "        #Clusters identification\n",
    "        if self.cluster_model == 'gaussian':\n",
    "            clf = GaussianMixture(n_components=self.n_components)\n",
    "        else:\n",
    "            clf = KMeans(n_clusters=self.n_components)\n",
    "        clf.fit(features)\n",
    "        groups=clf.predict(features)\n",
    "        labels=np.unique(groups)\n",
    "\n",
    "        #CATEs et ATEs calculations per cluster\n",
    "        for label in labels:\n",
    "            idx_group=groups==label             \n",
    "            if self.verbose ==True:\n",
    "                print(\"- Les dimensions du CATE pour le groupe {} sont de {}.\".format(label,cate_hat[idx_group].shape))\n",
    "            self.cates[label] = cate_hat[idx_group]\n",
    "            ate_hat =cate_hat[idx_group].mean()\n",
    "            if self.verbose ==True:\n",
    "                print(\"- L'estimation de la valeur de l'ATE pour le groupe {} = {}.\".format(label, ate_hat))\n",
    "            self.ates[label] = ate_hat\n",
    "\n",
    "    def predict_CATE(self, x, idx = None, cluster = False, clusters = None, n_components = 2, \n",
    "                     cluster_model = 'gaussian', clustering_method = 'hybrid', verbose=False):\n",
    "        \"\"\"\n",
    "        INPUTS:\n",
    "        x : samples of features x that will serve for prediction if self.cv = None\n",
    "        idx : np.array of boolean that will serve to idenfify which features of self.X will be used for prediction\n",
    "              if self.cv!=None\n",
    "        cluster :  boolean to describe if clustering shall be activated\n",
    "        clusters = np.array of lenght self.X witch provides labels for each features of self.X ( per example label {0,1})\n",
    "              if clusters is not provided the clusters will be calclated with the \"clustering_function\" with \"n_components\"\n",
    "        n_components : number of cluster to use if clusters = None and cluster = true, 2 per default\n",
    "        cluster_model : type of clustering model if clusters = None and cluster = true, can be 'gaussian' or 'kmeans'\n",
    "        clustering_method : type of clustreing features if clusters = None and cluster = true, \n",
    "              can be 'features', 'cate', 'hybrid'\n",
    "        verbose: boolean display of print, False per default\n",
    "        \n",
    "        OUTPUTS:\n",
    "        cates: np.array of lenght of x \n",
    "        \"\"\"\n",
    "        \n",
    "        self.cluster = cluster                        \n",
    "        self.clusters = clusters                      \n",
    "        self.n_components = n_components\n",
    "        self.cluster_model = cluster_model\n",
    "        self.approach = clustering_method\n",
    "        self.verbose = verbose\n",
    "        self.idx=idx\n",
    "        \n",
    "        #prediction with and without cv\n",
    "        if self.cv==None:\n",
    "            self.Y_0_hat = self.clf.predict(np.c_[x, np.zeros(len(x))])\n",
    "            self.Y_1_hat = self.clf.predict(np.c_[x, np.ones(len(x))])\n",
    "        else:\n",
    "            self.Y_0_hat = np.zeros((X.shape[0]))\n",
    "            self.Y_1_hat = np.zeros((X.shape[0]))\n",
    "            for i, (_, test) in enumerate(self.splits):\n",
    "                X_test = self.X[test]\n",
    "                self.Y_0_hat[test] = self.clfs[i].predict(np.c_[X_test, np.zeros(len(X_test))])\n",
    "                self.Y_1_hat[test] = self.clfs[i].predict(np.c_[X_test, np.ones(len(X_test))])\n",
    "            if isinstance(self.idx,np.ndarray):\n",
    "                assert(self.idx.dtype.type == np.bool_), 'must be a boolean'\n",
    "                self.Y_0_hat = self.Y_0_hat[self.idx]\n",
    "                self.Y_1_hat = self.Y_1_hat[self.idx]\n",
    "        \n",
    "        if self.cluster == False:\n",
    "            return self.Y_1_hat - self.Y_0_hat\n",
    "        else :\n",
    "            self.ates={}\n",
    "            self.cates={}\n",
    "            \n",
    "            if isinstance(self.clusters,np.ndarray)==False: \n",
    "                self.clustering_function()\n",
    "            else:\n",
    "                assert self.clusters.shape[0]==self.X.shape[0], 'dim of clusters doesn\\'t meet dim of observations'\n",
    "                labels=np.unique(self.clusters)\n",
    "                for label in labels:\n",
    "                    idx_group=self.clusters==label             \n",
    "                    self.cates[label] = (self.Y_1_hat - self.Y_0_hat)[idx_group]\n",
    "                    ate_hat =(self.Y_1_hat - self.Y_0_hat)[idx_group].mean()\n",
    "                    self.ates[label] = ate_hat\n",
    "            return self.cates\n",
    "\n",
    "    def predict_ATE(self):\n",
    "        if self.cluster == False:\n",
    "            return (self.Y_1_hat - self.Y_0_hat).mean()\n",
    "        else:\n",
    "            return self.ates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Les dimensions du CATE = (500,).\n",
      "- L'estimation de la valeur de l'ATE = 9.868469040652952.\n"
     ]
    }
   ],
   "source": [
    "slearner=iSLearner(base_estimator=RandomForestRegressor())\n",
    "slearner.fit(X,W,Y)\n",
    "\n",
    "cate_hat_S = slearner.predict_CATE(X)\n",
    "print(\"- Les dimensions du CATE = {}.\".format(cate_hat_S.shape))\n",
    "\n",
    "ate_hat_S = slearner.predict_ATE()\n",
    "print(\"- L'estimation de la valeur de l'ATE = {}.\".format(ate_hat_S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Les groupes du CATE = dict_keys([0, 1]).\n",
      "- L'estimation de la valeur de l'ATE = {0: 9.713121940451874, 1: 10.025883551561968}.\n"
     ]
    }
   ],
   "source": [
    "slearner=iSLearner(base_estimator=RandomForestRegressor())\n",
    "slearner.fit(X,W,Y)\n",
    "\n",
    "cate_hat_S = slearner.predict_CATE(X, cluster = True)\n",
    "print(\"- Les groupes du CATE = {}.\".format(cate_hat_S.keys()))\n",
    "\n",
    "ate_hat_S = slearner.predict_ATE()\n",
    "print(\"- L'estimation de la valeur de l'ATE = {}.\".format(ate_hat_S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Les dimensions du CATE pour le groupe complet sont de (500,).\n",
      "- L'estimation de la valeur de l'ATE pour le groupe complet = 9.853890453531093.\n",
      "- Les dimensions du CATE pour le groupe 0 sont de (250,).\n",
      "- L'estimation de la valeur de l'ATE pour le groupe 0 = 9.70323582046025.\n",
      "- Les dimensions du CATE pour le groupe 1 sont de (250,).\n",
      "- L'estimation de la valeur de l'ATE pour le groupe 1 = 10.004545086601937.\n",
      "- Les groupes du CATE = dict_keys([0, 1]).\n",
      "- L'estimation de la valeur de l'ATE = {0: 9.70323582046025, 1: 10.004545086601937}.\n"
     ]
    }
   ],
   "source": [
    "slearner=iSLearner(base_estimator=RandomForestRegressor())\n",
    "slearner.fit(X,W,Y)\n",
    "\n",
    "cate_hat_S = slearner.predict_CATE(X, cluster = True, verbose=True)\n",
    "print(\"- Les groupes du CATE = {}.\".format(cate_hat_S.keys()))\n",
    "\n",
    "ate_hat_S = slearner.predict_ATE()\n",
    "print(\"- L'estimation de la valeur de l'ATE = {}.\".format(ate_hat_S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Les groupes du CATE = dict_keys([0, 1, 2, 3, 4]).\n",
      "- L'estimation de la valeur de l'ATE = {0: 9.139660455437287, 1: 9.804843777884475, 2: 9.981569021958054, 3: 9.174404126304362, 4: 11.542343664922152}.\n"
     ]
    }
   ],
   "source": [
    "cate_hat_S = slearner.predict_CATE(X, cluster = True, n_components= 5)\n",
    "print(\"- Les groupes du CATE = {}.\".format(cate_hat_S.keys()))\n",
    "\n",
    "ate_hat_S = slearner.predict_ATE()\n",
    "print(\"- L'estimation de la valeur de l'ATE = {}.\".format(ate_hat_S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Les groupes du CATE = dict_keys([0, 1, 2, 3, 4]).\n",
      "- L'estimation de la valeur de l'ATE = {0: 9.897965068323348, 1: 11.977988638487577, 2: 9.192424315196183, 3: 9.542860515214782, 4: 11.052583805981891}.\n"
     ]
    }
   ],
   "source": [
    "cate_hat_S = slearner.predict_CATE(X, cluster = True, n_components= 5)\n",
    "print(\"- Les groupes du CATE = {}.\".format(cate_hat_S.keys()))\n",
    "\n",
    "ate_hat_S = slearner.predict_ATE()\n",
    "print(\"- L'estimation de la valeur de l'ATE = {}.\".format(ate_hat_S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Les groupes du CATE = dict_keys([0, 1]).\n",
      "- L'estimation de la valeur de l'ATE = {0: 9.846315955965606, 1: 9.860553733344343}.\n"
     ]
    }
   ],
   "source": [
    "clusters = np.random.randint(0,2,(X.shape[0]))\n",
    "cate_hat_S = slearner.predict_CATE(X, cluster = True, clusters = clusters, n_components= 5, \n",
    "                     cluster_model = 'kmeans', clustering_method = 'cate')\n",
    "print(\"- Les groupes du CATE = {}.\".format(cate_hat_S.keys()))\n",
    "\n",
    "ate_hat_S = slearner.predict_ATE()\n",
    "print(\"- L'estimation de la valeur de l'ATE = {}.\".format(ate_hat_S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Les dimensions du CATE = (500,).\n",
      "- L'estimation de la valeur de l'ATE = 9.890033361697293.\n"
     ]
    }
   ],
   "source": [
    "slearner=iSLearner(base_estimator=RandomForestRegressor())\n",
    "slearner.fit(X,W,Y,cv=10)\n",
    "\n",
    "cate_hat_S = slearner.predict_CATE(X)\n",
    "print(\"- Les dimensions du CATE = {}.\".format(cate_hat_S.shape))\n",
    "\n",
    "ate_hat_S = slearner.predict_ATE()\n",
    "print(\"- L'estimation de la valeur de l'ATE = {}.\".format(ate_hat_S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Les dimensions du CATE = (350,).\n",
      "- L'estimation de la valeur de l'ATE = 9.867773769671972.\n"
     ]
    }
   ],
   "source": [
    "idx = np.ones((X.shape[0]))\n",
    "idx[:150]=0\n",
    "idx= idx.astype(bool)\n",
    "\n",
    "slearner=iSLearner(base_estimator=RandomForestRegressor())\n",
    "slearner.fit(X,W,Y,cv=5)\n",
    "\n",
    "cate_hat_S = slearner.predict_CATE(X, idx=idx)\n",
    "print(\"- Les dimensions du CATE = {}.\".format(cate_hat_S.shape))\n",
    "\n",
    "ate_hat_S = slearner.predict_ATE()\n",
    "print(\"- L'estimation de la valeur de l'ATE = {}.\".format(ate_hat_S))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iTlearner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "class iTLearner(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\" Homemade TLearner class \"\"\"\n",
    "    \n",
    "    def __init__(self, base_estimator0=LinearRegression(), base_estimator1=LinearRegression() ):\n",
    "        # init\n",
    "        self.estimator0 = base_estimator0\n",
    "        self.estimator1 = base_estimator1\n",
    "\n",
    "    def fit(self, X, W, Y, cv = None):\n",
    "        self.X = X\n",
    "        self.W = W\n",
    "        self.Y = Y\n",
    "        self.cv =cv\n",
    "        if self.cv==None:\n",
    "            self.mu_0 = self.estimator0.fit(X[self.W==0,:], self.Y[self.W==0])\n",
    "            self.mu_1 = self.estimator1.fit(X[self.W==1,:], self.Y[self.W==1])\n",
    "        else:\n",
    "            assert isinstance(self.cv, int),'cv must be an integer'\n",
    "            self.kf = KFold(n_splits=self.cv, shuffle=False)\n",
    "            self.splits = list(self.kf.split(self.X,self.W,self.Y))\n",
    "            self.mu_0s = []\n",
    "            self.mu_1s = []\n",
    "            for train, _ in self.splits:\n",
    "                X_train = self.X[train]\n",
    "                Y_train = self.Y[train]\n",
    "                W_train = self.W[train]\n",
    "                self.mu_0s.append(clone(self.estimator0).fit(X_train[W_train==0,:], Y_train[W_train==0]))\n",
    "                self.mu_1s.append(clone(self.estimator1).fit(X_train[W_train==1,:], Y_train[W_train==1]))\n",
    "\n",
    "    def clustering_function(self):\n",
    "        \"\"\"\n",
    "        Clustering function\n",
    "        INPUTS:\n",
    "        see function predict_CATE\n",
    "        OUTPUTS:\n",
    "        returns dictionnaries of ates, cates \n",
    "        \"\"\"\n",
    "\n",
    "        #CATE et ATE calculation\n",
    "        cate_hat = self.Y_1_hat - self.Y_0_hat\n",
    "        if self.verbose ==True:    \n",
    "            print(\"- Les dimensions du CATE pour le groupe complet sont de {}.\".format(cate_hat.shape))    \n",
    "        if self.verbose ==True:\n",
    "            print(\"- L'estimation de la valeur de l'ATE pour le groupe complet = {}.\".format(cate_hat.mean()))\n",
    "\n",
    "        #features calculation\n",
    "        assert (self.approach=='hybrid' or \n",
    "                self.approach=='cate' or \n",
    "                self.approach=='features'), \"clustering method choosen differs from 'hybrid' or 'cate' or 'features'\"\n",
    "        if self.approach=='hybrid':\n",
    "            features = np.hstack((self.X,cate_hat.reshape(-1, 1)))\n",
    "        if self.approach=='cate':\n",
    "            features=cate_hat.reshape(-1, 1)\n",
    "        if self.approach=='features':\n",
    "            features=self.X\n",
    "\n",
    "        #Clusters identification\n",
    "        if self.cluster_model == 'gaussian':\n",
    "            clf = GaussianMixture(n_components=self.n_components)\n",
    "        else:\n",
    "            clf = KMeans(n_clusters=self.n_components)\n",
    "        clf.fit(features)\n",
    "        groups=clf.predict(features)\n",
    "        labels=np.unique(groups)\n",
    "\n",
    "        #CATEs et ATEs calculations per cluster\n",
    "        for label in labels:\n",
    "            idx_group=groups==label             \n",
    "            if self.verbose ==True:\n",
    "                print(\"- Les dimensions du CATE pour le groupe {} sont de {}.\".format(label,cate_hat[idx_group].shape))\n",
    "            self.cates[label] = cate_hat[idx_group]\n",
    "            ate_hat =cate_hat[idx_group].mean()\n",
    "            if self.verbose ==True:\n",
    "                print(\"- L'estimation de la valeur de l'ATE pour le groupe {} = {}.\".format(label, ate_hat))\n",
    "            self.ates[label] = ate_hat\n",
    "            \n",
    "    \n",
    "    def predict_CATE(self, x, idx = None, cluster = False, clusters = None, n_components = 2, \n",
    "                     cluster_model = 'gaussian', clustering_method = 'hybrid', verbose=False):\n",
    "        \"\"\"\n",
    "        INPUTS:\n",
    "        x : samples of features x that will serve for prediction if self.cv = None\n",
    "        idx : np.array of boolean that will serve to idenfify which features of self.X will be used for prediction\n",
    "              if self.cv!=None\n",
    "        cluster :  boolean to describe if clustering shall be activated\n",
    "        clusters = np.array of lenght self.X witch provides labels for each features of self.X ( per example label {0,1})\n",
    "              if clusters is not provided the clusters will be calclated with the \"clustering_function\" with \"n_components\"\n",
    "        n_components : number of cluster to use if clusters = None and cluster = true, 2 per default\n",
    "        cluster_model : type of clustering model if clusters = None and cluster = true, can be 'gaussian' or 'kmeans'\n",
    "        clustering_method : type of clustreing features if clusters = None and cluster = true, \n",
    "              can be 'features', 'cate', 'hybrid'\n",
    "        verbose: boolean display of print, False per default\n",
    "        \n",
    "        OUTPUTS:\n",
    "        cates: np.array of lenght of x \n",
    "        \"\"\"\n",
    "        \n",
    "        self.cluster = cluster                        \n",
    "        self.clusters = clusters                      \n",
    "        self.n_components = n_components\n",
    "        self.cluster_model = cluster_model\n",
    "        self.approach = clustering_method\n",
    "        self.verbose = verbose\n",
    "        self.idx=idx\n",
    "        \n",
    "        if self.cv==None:       \n",
    "            self.Y_0_hat = self.mu_0.predict(x)\n",
    "            self.Y_1_hat = self.mu_1.predict(x)\n",
    "        else:\n",
    "            self.Y_0_hat = np.zeros((X.shape[0]))\n",
    "            self.Y_1_hat = np.zeros((X.shape[0]))\n",
    "            for i, (_, test) in enumerate(self.splits):\n",
    "                X_test = self.X[test]\n",
    "                self.Y_0_hat[test] = self.mu_0s[i].predict(X_test)\n",
    "                self.Y_1_hat[test] = self.mu_1s[i].predict(X_test)\n",
    "            if isinstance(self.idx, np.ndarray):\n",
    "                assert(self.idx.dtype.type == np.bool_), 'must be a boolean'\n",
    "                self.Y_0_hat = self.Y_0_hat[self.idx]\n",
    "                self.Y_1_hat = self.Y_1_hat[self.idx]\n",
    "    \n",
    "        if self.cluster == False:\n",
    "            return self.Y_1_hat - self.Y_0_hat\n",
    "        else:\n",
    "            self.ates={}\n",
    "            self.cates={}\n",
    "            if isinstance(self.clusters,np.ndarray)==False: \n",
    "                self.clustering_function()\n",
    "            else:\n",
    "                assert self.clusters.shape[0]==self.X.shape[0], 'dim of clusters doesn\\'t meet dim of observations'\n",
    "                labels=np.unique(self.clusters)\n",
    "                for label in labels:\n",
    "                    idx_group=self.clusters==label             \n",
    "                    self.cates[label] = (self.Y_1_hat - self.Y_0_hat)[idx_group]\n",
    "                    ate_hat =(self.Y_1_hat - self.Y_0_hat)[idx_group].mean()\n",
    "                    self.ates[label] = ate_hat\n",
    "            return self.cates\n",
    "\n",
    "    def predict_ATE(self):\n",
    "        if self.cluster == False:\n",
    "            return (self.Y_1_hat - self.Y_0_hat).mean()\n",
    "        else:\n",
    "            return self.ates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Les dimensions du CATE = (500,).\n",
      "- L'estimation de la valeur de l'ATE = 9.937164492682962.\n"
     ]
    }
   ],
   "source": [
    "tlearner=iTLearner(base_estimator0=RandomForestRegressor(),base_estimator1=RandomForestRegressor())\n",
    "tlearner.fit(X,W,Y, cv=None)\n",
    "\n",
    "cate_hat_T = tlearner.predict_CATE(X)\n",
    "print(\"- Les dimensions du CATE = {}.\".format(cate_hat_T.shape))\n",
    "\n",
    "ate_hat_T = tlearner.predict_ATE()\n",
    "print(\"- L'estimation de la valeur de l'ATE = {}.\".format(ate_hat_T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Les dimensions du CATE = (500,).\n",
      "- L'estimation de la valeur de l'ATE = 9.91649581480164.\n"
     ]
    }
   ],
   "source": [
    "tlearner=iTLearner(base_estimator0=RandomForestRegressor(),base_estimator1=RandomForestRegressor())\n",
    "tlearner.fit(X,W,Y, cv=4)\n",
    "\n",
    "cate_hat_T = tlearner.predict_CATE(X)\n",
    "print(\"- Les dimensions du CATE = {}.\".format(cate_hat_T.shape))\n",
    "\n",
    "ate_hat_T = tlearner.predict_ATE()\n",
    "print(\"- L'estimation de la valeur de l'ATE = {}.\".format(ate_hat_T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Les dimensions du CATE = (400,).\n",
      "- L'estimation de la valeur de l'ATE = 9.875848547168152.\n"
     ]
    }
   ],
   "source": [
    "idx = np.ones((X.shape[0]))\n",
    "idx[:100]=0\n",
    "idx= idx.astype(bool)\n",
    "\n",
    "tlearner=iTLearner(base_estimator0=RandomForestRegressor(),base_estimator1=RandomForestRegressor())\n",
    "tlearner.fit(X,W,Y, cv=4)\n",
    "\n",
    "cate_hat_T = tlearner.predict_CATE(X, idx=idx)\n",
    "print(\"- Les dimensions du CATE = {}.\".format(cate_hat_T.shape))\n",
    "\n",
    "ate_hat_T = tlearner.predict_ATE()\n",
    "print(\"- L'estimation de la valeur de l'ATE = {}.\".format(ate_hat_T))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Les groupes du CATE = dict_keys([0, 1]).\n",
      "- L'estimation de la valeur de l'ATE = {0: 9.811633949850442, 1: 9.998423545200886}.\n"
     ]
    }
   ],
   "source": [
    "tlearner=iTLearner(base_estimator0=RandomForestRegressor(),base_estimator1=RandomForestRegressor())\n",
    "tlearner.fit(X,W,Y)\n",
    "\n",
    "cate_hat_T = tlearner.predict_CATE(X, cluster = True)\n",
    "print(\"- Les groupes du CATE = {}.\".format(cate_hat_T.keys()))\n",
    "\n",
    "ate_hat_T = tlearner.predict_ATE()\n",
    "print(\"- L'estimation de la valeur de l'ATE = {}.\".format(ate_hat_T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Les groupes du CATE = dict_keys([0, 1, 2, 3, 4]).\n",
      "- L'estimation de la valeur de l'ATE = {0: 10.929611196710434, 1: 10.440675899914055, 2: 9.028115273796042, 3: 11.527399660531017, 4: 9.560909562172391}.\n"
     ]
    }
   ],
   "source": [
    "cate_hat_T = tlearner.predict_CATE(X, cluster = True, n_components= 5)\n",
    "print(\"- Les groupes du CATE = {}.\".format(cate_hat_T.keys()))\n",
    "\n",
    "ate_hat_T = tlearner.predict_ATE()\n",
    "print(\"- L'estimation de la valeur de l'ATE = {}.\".format(ate_hat_T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Les groupes du CATE = dict_keys([0, 1]).\n",
      "- L'estimation de la valeur de l'ATE = {0: 9.869899608372787, 1: 9.94006308336009}.\n"
     ]
    }
   ],
   "source": [
    "clusters = np.random.randint(0,2,(X.shape[0]))\n",
    "cate_hat_T = tlearner.predict_CATE(X, cluster = True, clusters = clusters, n_components= 5, \n",
    "                     cluster_model = 'kmeans', clustering_method = 'cate')\n",
    "print(\"- Les groupes du CATE = {}.\".format(cate_hat_T.keys()))\n",
    "\n",
    "ate_hat_T = tlearner.predict_ATE()\n",
    "print(\"- L'estimation de la valeur de l'ATE = {}.\".format(ate_hat_T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iXLearner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "class iXLearner(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\" Homemade XLearner class \"\"\"\n",
    "    \n",
    "    def __init__(self, outcome_learner0 = LinearRegression(), outcome_learner1 = LinearRegression(), \n",
    "                 effect_learner0 = LinearRegression(), effect_learner1 = LinearRegression()):\n",
    "        # init\n",
    "        self.outcome_learner0 = outcome_learner0\n",
    "        self.outcome_learner1 = outcome_learner1\n",
    "        self.effect_learner0 = effect_learner0\n",
    "        self.effect_learner1 = effect_learner1\n",
    "\n",
    "    def fit(self, X, W, Y, cv = None):\n",
    "        # Initiation des variables\n",
    "        self.X = X\n",
    "        self.W = W\n",
    "        self.Y = Y\n",
    "        self.cv = cv\n",
    "        \n",
    "        if self.cv == None:\n",
    "            \n",
    "            #Stage 1 : Estimate the average outcomes μ0(x) and  μ1(x)\n",
    "            self.mu_0 = self.outcome_learner0.fit(self.X[self.W==0,:], self.Y[self.W==0])\n",
    "            self.mu_1 = self.outcome_learner1.fit(self.X[self.W==1,:], self.Y[self.W==1])\n",
    "\n",
    "            #Stage 2 : Impute the user level treatment effects\n",
    "            self.D0 = self.mu_1.predict(X[self.W==0,:]) - self.Y[self.W==0]\n",
    "            self.D1 = self.Y[self.W==1] - self.mu_0.predict(X[self.W==1,:])    \n",
    "            \n",
    "            #estimate τ1(x) = E[D1|X=x], and τ0(x) = E[D0|X=x] using machine learning models:\n",
    "            self.tau_0 = self.effect_learner0.fit(X[self.W==0,:], self.D0)\n",
    "            self.tau_1 = self.effect_learner1.fit(X[self.W==1,:], self.D1)\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            assert isinstance(self.cv, int),'cv must be an integer'\n",
    "            self.kf = KFold(n_splits=self.cv, shuffle=False)\n",
    "            \n",
    "            #stage 1 and 2\n",
    "            self.splits_0 = list(self.kf.split(self.X[self.W==0,:],self.Y[self.W==0]))\n",
    "            self.splits_1 = list(self.kf.split(self.X[self.W==1,:],self.Y[self.W==1]))\n",
    "            self.D0 = np.zeros((self.X[self.W==0,:].shape[0]))\n",
    "            self.D1 = np.zeros((self.X[self.W==1,:].shape[0]))\n",
    "            for (train0, test0), (train1, test1) in zip(self.splits_0, self.splits_1):\n",
    "                X_train0, X_test0,  = self.X[self.W==0,:][train0], self.X[self.W==0,:][test0]\n",
    "                X_train1, X_test1  = self.X[self.W==1,:][train1], self.X[self.W==1,:][test1]\n",
    "                Y_train0, Y_test0 = self.Y[self.W==0][train0], self.Y[self.W==0][test0]\n",
    "                Y_train1, Y_test1 = self.Y[self.W==1][train1], self.Y[self.W==1][test1]\n",
    "                mu_0 = self.outcome_learner0.fit(X_train0, Y_train0)\n",
    "                mu_1 = self.outcome_learner1.fit(X_train1, Y_train1)\n",
    "                self.D0[test0] = mu_1.predict(X_test0) - Y_test0\n",
    "                self.D1[test1] = Y_test1 - mu_0.predict(X_test1)\n",
    "            self.D = np.zeros((self.X.shape[0]))\n",
    "            self.D[self.W==0], self.D[self.W==1] = self.D0, self.D1\n",
    "            #estimate τ1(x) = E[D1|X=x], and τ0(x) = E[D0|X=x] using machine learning models:\n",
    "            self.tau_0s = []\n",
    "            self.tau_1s = []\n",
    "            self.splits = list(self.kf.split(self.X,self.W,self.D))\n",
    "            for train, test in self.splits:\n",
    "                X_train = self.X[train]\n",
    "                W_train = self.W[train]\n",
    "                D_train = self.D[train]\n",
    "                self.tau_0s.append(clone(self.effect_learner0).fit(X_train[W_train==0,:], D_train[W_train==0]))\n",
    "                self.tau_1s.append(clone(self.effect_learner1).fit(X_train[W_train==1,:], D_train[W_train==1]))\n",
    "    \n",
    "    def propensity_score(self, clf = LogisticRegression()):\n",
    "        \"\"\"\n",
    "        This function fits a classifier to automaticcaly calculates the propensity score\n",
    "        INPUTS:\n",
    "        self.X and self.W\n",
    "        OUTPUTS:\n",
    "        n fitted clf classifier(s) depending on number of folds of cv\n",
    "        \"\"\"\n",
    "        self.cls = CalibratedClassifierCV(clf)\n",
    "        if self.cv == None: \n",
    "            self.cls.fit(self.X, self.W)           \n",
    "        else:\n",
    "            self.clss = []\n",
    "            for train, test in self.splits:\n",
    "                X_train, X_test = self.X[train], self.X[test]\n",
    "                W_train = W[train]\n",
    "                self.clss.append(clone(self.cls).fit(X_train, W_train))   \n",
    "    \n",
    "    def clustering_function(self):\n",
    "        \"\"\"\n",
    "        Clustering function\n",
    "        INPUTS:\n",
    "        see function predict_CATE\n",
    "        OUTPUTS:\n",
    "        returns dictionnaries of ates, cates \n",
    "        \"\"\"\n",
    "\n",
    "        #CATE et ATE calculation\n",
    "        cate_hat = self.CATE_hat\n",
    "        if self.verbose ==True:    \n",
    "            print(\"- Les dimensions du CATE pour le groupe complet sont de {}.\".format(cate_hat.shape))    \n",
    "        if self.verbose ==True:\n",
    "            print(\"- L'estimation de la valeur de l'ATE pour le groupe complet = {}.\".format(cate_hat.mean()))\n",
    "\n",
    "        #features calculation\n",
    "        assert (self.approach=='hybrid' or \n",
    "                self.approach=='cate' or \n",
    "                self.approach=='features'), \"clustering method choosen differs from 'hybrid' or 'cate' or 'features'\"\n",
    "        if self.approach=='hybrid':\n",
    "            features = np.hstack((self.X,cate_hat.reshape(-1, 1)))\n",
    "        if self.approach=='cate':\n",
    "            features=cate_hat.reshape(-1, 1)\n",
    "        if self.approach=='features':\n",
    "            features=self.X\n",
    "\n",
    "        #Clusters identification\n",
    "        if self.cluster_model == 'gaussian':\n",
    "            clf = GaussianMixture(n_components=self.n_components)\n",
    "        else:\n",
    "            clf = KMeans(n_clusters=self.n_components)\n",
    "        clf.fit(features)\n",
    "        groups=clf.predict(features)\n",
    "        labels=np.unique(groups)\n",
    "\n",
    "        #CATEs et ATEs calculations per cluster\n",
    "        for label in labels:\n",
    "            idx_group=groups==label             \n",
    "            if self.verbose ==True:\n",
    "                print(\"- Les dimensions du CATE pour le groupe {} sont de {}.\".format(label,cate_hat[idx_group].shape))\n",
    "            self.cates[label] = cate_hat[idx_group]\n",
    "            ate_hat =cate_hat[idx_group].mean()\n",
    "            if self.verbose ==True:\n",
    "                print(\"- L'estimation de la valeur de l'ATE pour le groupe {} = {}.\".format(label, ate_hat))\n",
    "            self.ates[label] = ate_hat\n",
    "\n",
    "    def predict_CATE(self, x, idx = None, cluster = False, clusters = None, n_components = 2, \n",
    "                     cluster_model = 'gaussian', clustering_method = 'hybrid', verbose=False):\n",
    "        \"\"\"\n",
    "        INPUTS:\n",
    "        x : samples of features x that will serve for prediction if self.cv = None\n",
    "        idx : np.array of boolean that will serve to idenfify which features of self.X will be used for prediction\n",
    "              if self.cv!=None\n",
    "        cluster :  boolean to describe if clustering shall be activated\n",
    "        clusters = np.array of lenght self.X witch provides labels for each features of self.X ( per example label {0,1})\n",
    "              if clusters is not provided the clusters will be calclated with the \"clustering_function\" with \"n_components\"\n",
    "        n_components : number of cluster to use if clusters = None and cluster = true, 2 per default\n",
    "        cluster_model : type of clustering model if clusters = None and cluster = true, can be 'gaussian' or 'kmeans'\n",
    "        clustering_method : type of clustreing features if clusters = None and cluster = true, \n",
    "              can be 'features', 'cate', 'hybrid'\n",
    "        verbose: boolean display of print, False per default\n",
    "        \n",
    "        OUTPUTS:\n",
    "        cates: np.array of lenght of x \n",
    "        \"\"\"\n",
    "        \n",
    "        self.cluster = cluster                        \n",
    "        self.clusters = clusters                      \n",
    "        self.n_components = n_components\n",
    "        self.cluster_model = cluster_model\n",
    "        self.approach = clustering_method\n",
    "        self.verbose = verbose\n",
    "        self.idx=idx\n",
    "               \n",
    "        self.propensity_score()\n",
    "        if self.cv==None:\n",
    "            self.propensity = self.cls.predict_proba(x)[:,1]\n",
    "            self.CATE_hat = self.propensity*self.tau_0.predict(x) + (1-self.propensity)*self.tau_1.predict(x)\n",
    "        else:\n",
    "            self.CATE_hat = np.zeros((X.shape[0]))\n",
    "            self.propensity = np.zeros((X.shape[0]))\n",
    "            for i, (_, test) in enumerate(self.splits):\n",
    "                X_test = self.X[test]\n",
    "                self.propensity[test] = self.clss[i].predict_proba(X_test)[:,1]\n",
    "                self.CATE_hat[test] = self.propensity[test]*self.tau_0s[i].predict(X_test) + (1-self.propensity)[test]*self.tau_1s[i].predict(X_test)\n",
    "            if isinstance(self.idx, np.ndarray):\n",
    "                assert(self.idx.dtype.type == np.bool_), 'must be a boolean'\n",
    "                self.CATE_hat = self.CATE_hat[self.idx]\n",
    "        \n",
    "        if self.cluster == False:\n",
    "            return self.CATE_hat\n",
    "        else:\n",
    "            self.ates={}\n",
    "            self.cates={}\n",
    "            if isinstance(self.clusters,np.ndarray)==False: \n",
    "                self.clustering_function()\n",
    "            else:\n",
    "                assert self.clusters.shape[0]==self.X.shape[0], 'dim of clusters doesn\\'t meet dim of observations'\n",
    "                labels=np.unique(self.clusters)\n",
    "                for label in labels:\n",
    "                    idx_group=self.clusters==label             \n",
    "                    self.cates[label] = self.CATE_hat[idx_group]\n",
    "                    ate_hat =self.CATE_hat[idx_group].mean()\n",
    "                    self.ates[label] = ate_hat\n",
    "            return self.cates\n",
    "\n",
    "    def predict_ATE(self):\n",
    "        if self.cluster == False:\n",
    "            return (self.CATE_hat).mean()\n",
    "        else:\n",
    "            return self.ates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Les dimensions du CATE = (500,).\n",
      "- L'estimation de la valeur de l'ATE = 9.965936668514333.\n"
     ]
    }
   ],
   "source": [
    "xlearner=iXLearner(outcome_learner0=RandomForestRegressor(),outcome_learner1=RandomForestRegressor())\n",
    "xlearner.fit(X,W,Y, cv=None)\n",
    "\n",
    "cate_hat_X = xlearner.predict_CATE(X)\n",
    "print(\"- Les dimensions du CATE = {}.\".format(cate_hat_X.shape))\n",
    "\n",
    "ate_hat_X = xlearner.predict_ATE()\n",
    "print(\"- L'estimation de la valeur de l'ATE = {}.\".format(ate_hat_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Les dimensions du CATE = (500,).\n",
      "- L'estimation de la valeur de l'ATE = 9.941678851073599.\n"
     ]
    }
   ],
   "source": [
    "xlearner=iXLearner(outcome_learner0=RandomForestRegressor(),outcome_learner1=RandomForestRegressor())\n",
    "xlearner.fit(X,W,Y, cv=5)\n",
    "\n",
    "cate_hat_X = xlearner.predict_CATE(X)\n",
    "print(\"- Les dimensions du CATE = {}.\".format(cate_hat_X.shape))\n",
    "\n",
    "ate_hat_X = xlearner.predict_ATE()\n",
    "print(\"- L'estimation de la valeur de l'ATE = {}.\".format(ate_hat_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Les dimensions du CATE = (490,).\n",
      "- L'estimation de la valeur de l'ATE = 9.955169386227153.\n"
     ]
    }
   ],
   "source": [
    "idx = np.ones((X.shape[0]))\n",
    "idx[:10]=0\n",
    "idx= idx.astype(bool)\n",
    "\n",
    "xlearner=iXLearner(outcome_learner0=RandomForestRegressor(),outcome_learner1=RandomForestRegressor())\n",
    "xlearner.fit(X,W,Y, cv=5)\n",
    "\n",
    "cate_hat_X = xlearner.predict_CATE(X, idx=idx)\n",
    "print(\"- Les dimensions du CATE = {}.\".format(cate_hat_X.shape))\n",
    "\n",
    "ate_hat_X = xlearner.predict_ATE()\n",
    "print(\"- L'estimation de la valeur de l'ATE = {}.\".format(ate_hat_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Les groupes du CATE = dict_keys([0, 1]).\n",
      "- L'estimation de la valeur de l'ATE = {0: 9.89803952914515, 1: 9.98940257112163}.\n"
     ]
    }
   ],
   "source": [
    "xlearner=iXLearner(outcome_learner0=RandomForestRegressor(),outcome_learner1=RandomForestRegressor())\n",
    "xlearner.fit(X,W,Y)\n",
    "\n",
    "cate_hat_X = xlearner.predict_CATE(X, cluster = True)\n",
    "print(\"- Les groupes du CATE = {}.\".format(cate_hat_X.keys()))\n",
    "\n",
    "ate_hat_X = xlearner.predict_ATE()\n",
    "print(\"- L'estimation de la valeur de l'ATE = {}.\".format(ate_hat_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Les groupes du CATE = dict_keys([0, 1]).\n",
      "- L'estimation de la valeur de l'ATE = {0: 9.941168161031777, 1: 9.958085849710374}.\n"
     ]
    }
   ],
   "source": [
    "xlearner=iXLearner(outcome_learner0=RandomForestRegressor(),outcome_learner1=RandomForestRegressor())\n",
    "xlearner.fit(X,W,Y, cv=5)\n",
    "\n",
    "cate_hat_X = xlearner.predict_CATE(X, cluster = True)\n",
    "print(\"- Les groupes du CATE = {}.\".format(cate_hat_X.keys()))\n",
    "\n",
    "ate_hat_X = xlearner.predict_ATE()\n",
    "print(\"- L'estimation de la valeur de l'ATE = {}.\".format(ate_hat_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Les groupes du CATE = dict_keys([0, 1, 2, 3, 4]).\n",
      "- L'estimation de la valeur de l'ATE = {0: 9.941168161031777, 1: 9.791842139710429, 2: 9.513640005225874, 3: 10.410959268894576, 4: 10.081246485523764}.\n"
     ]
    }
   ],
   "source": [
    "cate_hat_X = xlearner.predict_CATE(X, cluster = True, n_components= 5)\n",
    "print(\"- Les groupes du CATE = {}.\".format(cate_hat_X.keys()))\n",
    "\n",
    "ate_hat_X = xlearner.predict_ATE()\n",
    "print(\"- L'estimation de la valeur de l'ATE = {}.\".format(ate_hat_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Les groupes du CATE = dict_keys([0, 1]).\n",
      "- L'estimation de la valeur de l'ATE = {0: 9.928090451052093, 1: 9.970220118427756}.\n"
     ]
    }
   ],
   "source": [
    "clusters = np.random.randint(0,2,(X.shape[0]))\n",
    "cate_hat_X = xlearner.predict_CATE(X, cluster = True, clusters = clusters, n_components= 5, \n",
    "                     cluster_model = 'kmeans', clustering_method = 'cate')\n",
    "print(\"- Les groupes du CATE = {}.\".format(cate_hat_X.keys()))\n",
    "\n",
    "ate_hat_X = xlearner.predict_ATE()\n",
    "print(\"- L'estimation de la valeur de l'ATE = {}.\".format(ate_hat_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iDRLearner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "class iDRLearner(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\" Homemade DRLearner class \"\"\"\n",
    "    \n",
    "    def __init__(self, model_regression = LinearRegression(), model_propensity = LogisticRegression(), \n",
    "                 model_final = LinearRegression()):\n",
    "        # init\n",
    "        self.model_regression = model_regression\n",
    "        self.model_propensity = model_propensity\n",
    "        self.model_final = model_final\n",
    "        \n",
    "\n",
    "    def fit(self, X, W, Y, cv = None):\n",
    "        # Initiation des variables\n",
    "        self.X = X\n",
    "        self.W = W\n",
    "        self.Y = Y \n",
    "        self.cv = cv\n",
    "        \n",
    "        if self.cv == None:\n",
    "            #Stage 1 : Regression of the outcomes μ(X,T) = E[Y|X,W,T]\n",
    "            self.features = np.hstack((self.X, self.W[:,np.newaxis]))\n",
    "            self.mu = self.model_regression.fit(self.features, self.Y)\n",
    "\n",
    "            #Stage 1 : Model to estimate the propensity_score\n",
    "            self.model_propensity = CalibratedClassifierCV(self.model_propensity)\n",
    "            self.model_propensity.fit(self.X, self.W)\n",
    "            self.propensity = self.model_propensity.predict_proba(X)\n",
    "\n",
    "            #Stage 1 : predict Y_pred\n",
    "            self.Y_pred_0 = self.mu.predict(np.hstack((self.X, np.zeros((self.X.shape[0],1)))))\n",
    "            self.Y_pred_0 += (self.Y - self.Y_pred_0) * (1 - self.W) / self.propensity[:,0]\n",
    "            self.Y_pred_1 = self.mu.predict(np.hstack((self.X, np.ones((self.X.shape[0],1)))))\n",
    "            self.Y_pred_1 += (self.Y - self.Y_pred_1) * (self.W) / self.propensity[:,1]\n",
    "\n",
    "            #Stage 2 : fit model final\n",
    "            self.model_final.fit(self.X, self.Y_pred_1 - self.Y_pred_0)\n",
    "        else:\n",
    "            assert isinstance(self.cv, int),'cv must be an integer'\n",
    "            self.kf = KFold(n_splits=self.cv, shuffle=False)\n",
    "            self.splits = list(self.kf.split(self.X, self.W, self.Y))\n",
    "            self.Y_pred_0 = np.zeros((self.X.shape[0]))\n",
    "            self.Y_pred_1 = np.zeros((self.X.shape[0]))\n",
    "            self.propensity = np.zeros((self.X.shape[0],2))\n",
    "            for train, test in self.splits:\n",
    "                X_train, X_test = self.X[train], self.X[test]\n",
    "                Y_train, Y_test = self.Y[train], self.Y[test]\n",
    "                W_train, W_test = self.W[train], self.W[test]\n",
    "                #Stage 1 : Regression of the outcomes μ(X,T) = E[Y|X,W,T]\n",
    "                features = np.hstack((X_train, W_train[:,np.newaxis]))\n",
    "                mu = self.model_regression.fit(features, Y_train)\n",
    "                #Stage 1 : Model to estimate the propensity_score\n",
    "                model_propensity = CalibratedClassifierCV(self.model_propensity)\n",
    "                model_propensity.fit(X_train, W_train)\n",
    "                self.propensity[test,:] = model_propensity.predict_proba(X_test)\n",
    "                #Stage 1 : predict Y_pred\n",
    "                self.Y_pred_0[test] = mu.predict(np.hstack((X_test, np.zeros((X_test.shape[0],1)))))\n",
    "                self.Y_pred_0[test] += (Y_test - self.Y_pred_0[test]) * (1 - W_test) / self.propensity[test,0]\n",
    "                self.Y_pred_1[test]  = mu.predict(np.hstack((X_test, np.ones((X_test.shape[0],1)))))\n",
    "                self.Y_pred_1[test] += (Y_test - self.Y_pred_1[test]) * W_test / self.propensity[test,1]\n",
    "            \n",
    "            #Stage 2 : fit finals model \n",
    "            self.model_finals= []\n",
    "            for train, test in self.splits:\n",
    "                X_train = self.X[train]\n",
    "                self.model_finals.append(clone(self.model_final).fit(X_train, self.Y_pred_1[train] - self.Y_pred_0[train]))   \n",
    "\n",
    "    def clustering_function(self):\n",
    "        \"\"\"\n",
    "        Clustering function\n",
    "        INPUTS:\n",
    "        see function predict_CATE\n",
    "        OUTPUTS:\n",
    "        returns dictionnaries of ates, cates \n",
    "        \"\"\"\n",
    "\n",
    "        #CATE et ATE calculation\n",
    "        cate_hat = self.CATE_hat\n",
    "        if self.verbose ==True:    \n",
    "            print(\"- Les dimensions du CATE pour le groupe complet sont de {}.\".format(cate_hat.shape))    \n",
    "        if self.verbose ==True:\n",
    "            print(\"- L'estimation de la valeur de l'ATE pour le groupe complet = {}.\".format(cate_hat.mean()))\n",
    "\n",
    "        #features calculation\n",
    "        assert (self.approach=='hybrid' or \n",
    "                self.approach=='cate' or \n",
    "                self.approach=='features'), \"clustering method choosen differs from 'hybrid' or 'cate' or 'features'\"\n",
    "        if self.approach=='hybrid':\n",
    "            features = np.hstack((self.X,cate_hat.reshape(-1, 1)))\n",
    "        if self.approach=='cate':\n",
    "            features=cate_hat.reshape(-1, 1)\n",
    "        if self.approach=='features':\n",
    "            features=self.X\n",
    "\n",
    "        #Clusters identification\n",
    "        if self.cluster_model == 'gaussian':\n",
    "            clf = GaussianMixture(n_components=self.n_components)\n",
    "        else:\n",
    "            clf = KMeans(n_clusters=self.n_components)\n",
    "        clf.fit(features)\n",
    "        groups=clf.predict(features)\n",
    "        labels=np.unique(groups)\n",
    "\n",
    "        #CATEs et ATEs calculations per cluster\n",
    "        for label in labels:\n",
    "            idx_group=groups==label             \n",
    "            if self.verbose ==True:\n",
    "                print(\"- Les dimensions du CATE pour le groupe {} sont de {}.\".format(label,cate_hat[idx_group].shape))\n",
    "            self.cates[label] = cate_hat[idx_group]\n",
    "            ate_hat =cate_hat[idx_group].mean()\n",
    "            if self.verbose ==True:\n",
    "                print(\"- L'estimation de la valeur de l'ATE pour le groupe {} = {}.\".format(label, ate_hat))\n",
    "            self.ates[label] = ate_hat\n",
    "    \n",
    "    def predict_CATE(self, x, idx = None, cluster = False, clusters = None, n_components = 2, \n",
    "                     cluster_model = 'gaussian', clustering_method = 'hybrid', verbose=False):\n",
    "        \"\"\"\n",
    "        INPUTS:\n",
    "        x : samples of features x that will serve for prediction if self.cv = None\n",
    "        idx : np.array of boolean that will serve to idenfify which features of self.X will be used for prediction\n",
    "              if self.cv!=None\n",
    "        cluster :  boolean to describe if clustering shall be activated\n",
    "        clusters = np.array of lenght self.X witch provides labels for each features of self.X ( per example label {0,1})\n",
    "              if clusters is not provided the clusters will be calclated with the \"clustering_function\" with \"n_components\"\n",
    "        n_components : number of cluster to use if clusters = None and cluster = true, 2 per default\n",
    "        cluster_model : type of clustering model if clusters = None and cluster = true, can be 'gaussian' or 'kmeans'\n",
    "        clustering_method : type of clustreing features if clusters = None and cluster = true, \n",
    "              can be 'features', 'cate', 'hybrid'\n",
    "        verbose: boolean display of print, False per default\n",
    "        \n",
    "        OUTPUTS:\n",
    "        cates: np.array of lenght of x \n",
    "        \"\"\"\n",
    "        self.cluster = cluster                        \n",
    "        self.clusters = clusters                      \n",
    "        self.n_components = n_components\n",
    "        self.cluster_model = cluster_model\n",
    "        self.approach = clustering_method\n",
    "        self.verbose = verbose\n",
    "        self.idx=idx\n",
    "        \n",
    "        if self.cv == None:\n",
    "            self.CATE_hat = self.model_final.predict(x)\n",
    "        else:\n",
    "            self.CATE_hat = np.zeros((X.shape[0]))\n",
    "            for i, (_, test) in enumerate(self.splits):\n",
    "                X_test = self.X[test]\n",
    "                self.CATE_hat[test] = self.model_finals[i].predict(X_test)\n",
    "            if isinstance(self.idx, np.ndarray):\n",
    "                assert(self.idx.dtype.type == np.bool_), 'must be a boolean'\n",
    "                self.CATE_hat = self.CATE_hat[self.idx]\n",
    "        \n",
    "        if self.cluster == False:\n",
    "            return self.CATE_hat\n",
    "        else:\n",
    "            self.ates={}\n",
    "            self.cates={}\n",
    "            if isinstance(self.clusters,np.ndarray)==False: \n",
    "                self.clustering_function()\n",
    "            else:\n",
    "                assert self.clusters.shape[0]==self.X.shape[0], 'dim of clusters doesn\\'t meet dim of observations'\n",
    "                labels=np.unique(self.clusters)\n",
    "                for label in labels:\n",
    "                    idx_group=self.clusters==label             \n",
    "                    self.cates[label] = self.CATE_hat[idx_group]\n",
    "                    ate_hat =self.CATE_hat[idx_group].mean()\n",
    "                    self.ates[label] = ate_hat\n",
    "            return self.cates\n",
    "\n",
    "    def predict_ATE(self):\n",
    "        if self.cluster == False:\n",
    "            return (self.CATE_hat).mean()\n",
    "        else:\n",
    "            return self.ates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Les dimensions du CATE = (500,).\n",
      "- L'estimation de la valeur de l'ATE = 10.02076808643905.\n"
     ]
    }
   ],
   "source": [
    "drlearner=iDRLearner()\n",
    "drlearner.fit(X,W,Y)\n",
    "\n",
    "cate_hat_D = drlearner.predict_CATE(X)\n",
    "print(\"- Les dimensions du CATE = {}.\".format(cate_hat_D.shape))\n",
    "\n",
    "ate_hat_D = drlearner.predict_ATE()\n",
    "print(\"- L'estimation de la valeur de l'ATE = {}.\".format(ate_hat_D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Les dimensions du CATE = (500,).\n",
      "- L'estimation de la valeur de l'ATE = 10.0282471973936.\n"
     ]
    }
   ],
   "source": [
    "drlearner=iDRLearner()\n",
    "drlearner.fit(X,W,Y, cv = 10)\n",
    "\n",
    "cate_hat_D = drlearner.predict_CATE(X)\n",
    "print(\"- Les dimensions du CATE = {}.\".format(cate_hat_D.shape))\n",
    "\n",
    "ate_hat_D = drlearner.predict_ATE()\n",
    "print(\"- L'estimation de la valeur de l'ATE = {}.\".format(ate_hat_D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Les dimensions du CATE = (500,).\n",
      "- L'estimation de la valeur de l'ATE = 10.0282471973936.\n"
     ]
    }
   ],
   "source": [
    "idx = np.ones((X.shape[0]))\n",
    "idx[:100]=0\n",
    "idx= idx.astype(bool)\n",
    "\n",
    "drlearner=iDRLearner()\n",
    "drlearner.fit(X,W,Y, cv = 10)\n",
    "\n",
    "cate_hat_D = drlearner.predict_CATE(X)\n",
    "print(\"- Les dimensions du CATE = {}.\".format(cate_hat_D.shape))\n",
    "\n",
    "ate_hat_D = drlearner.predict_ATE()\n",
    "print(\"- L'estimation de la valeur de l'ATE = {}.\".format(ate_hat_D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Les groupes du CATE = dict_keys([0, 1]).\n",
      "- L'estimation de la valeur de l'ATE = {0: 10.011228000356045, 1: 10.04554089760918}.\n"
     ]
    }
   ],
   "source": [
    "drlearner=iDRLearner()\n",
    "drlearner.fit(X,W,Y, cv = 10)\n",
    "\n",
    "cate_hat_D = drlearner.predict_CATE(X, cluster = True)\n",
    "print(\"- Les groupes du CATE = {}.\".format(cate_hat_D.keys()))\n",
    "\n",
    "ate_hat_D = drlearner.predict_ATE()\n",
    "print(\"- L'estimation de la valeur de l'ATE = {}.\".format(ate_hat_D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Les groupes du CATE = dict_keys([0, 1, 2, 3, 4]).\n",
      "- L'estimation de la valeur de l'ATE = {0: 10.014695380561484, 1: 10.008960018268516, 2: 10.060294152966817, 3: 10.128735775486929, 4: 9.915724711015635}.\n"
     ]
    }
   ],
   "source": [
    "cate_hat_D = drlearner.predict_CATE(X, cluster = True, n_components=5)\n",
    "print(\"- Les groupes du CATE = {}.\".format(cate_hat_D.keys()))\n",
    "\n",
    "ate_hat_D = drlearner.predict_ATE()\n",
    "print(\"- L'estimation de la valeur de l'ATE = {}.\".format(ate_hat_D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Les groupes du CATE = dict_keys([0, 1]).\n",
      "- L'estimation de la valeur de l'ATE = {0: 10.03377115952771, 1: 10.023024151484696}.\n"
     ]
    }
   ],
   "source": [
    "clusters = np.random.randint(0,2,(X.shape[0]))\n",
    "cate_hat_D = drlearner.predict_CATE(X, cluster = True, clusters = clusters, n_components= 5, \n",
    "                     cluster_model = 'kmeans', clustering_method = 'cate')\n",
    "print(\"- Les groupes du CATE = {}.\".format(cate_hat_D.keys()))\n",
    "\n",
    "ate_hat_D = drlearner.predict_ATE()\n",
    "print(\"- L'estimation de la valeur de l'ATE = {}.\".format(ate_hat_D))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparatif des modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(columns = ['SLearner' , 'TLearner', 'XLearner' , 'DRLearner'], index=['0.5', '0.1', 'hybrid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: LinearRegression(),\n",
       " 1: RandomForestRegressor(),\n",
       " 2: GradientBoostingRegressor()}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "models ={0: LinearRegression(), 1: RandomForestRegressor(), 2:GradientBoostingRegressor()}\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 2\n",
    "N = 1000\n",
    "d = 2                                       # d = 2, afin de pouvoir être calculé par intégration et par Monte Carlo\n",
    "p = None\n",
    "beta0 = np.random.uniform(1, 30, (1, d))\n",
    "beta1 = np.random.uniform(1,30, (1, d))\n",
    "beta = np.vstack((beta0,beta1))               # beta0 = beta1           \n",
    "bias = np.array([100,10])                 # beta0 = beta1, cas simple pour faciliter l'interprétation des résultats                              # Gamma0 != Gamma1, biais différent\n",
    "f = lambda x:x\n",
    "g = lambda x:x\n",
    "\n",
    "# Génération des données\n",
    "X, W, Y = causal_generation(N, d, beta, bias, f, g, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "slearner = SLearner(base_estimator=models[i])\n",
    "tlearner = TLearner(base_estimator0=models[i],base_estimator1=deepcopy(models[i]))\n",
    "xlearner = XLearner(outcome_learner0 = models[i], outcome_learner1 = deepcopy(models[i]), \n",
    "                 effect_learner0 = deepcopy(models[i]), effect_learner1 = deepcopy(models[i]))\n",
    "drlearner = DRLearner(model_regression = models[i], model_propensity = LogisticRegression(), \n",
    "                 model_final = deepcopy(models[i]))\n",
    "metalearners = { 'Slearner' : slearner,\n",
    "              'TLearner' : tlearner,\n",
    "               'XLearner' : xlearner,\n",
    "               'DRLearner' : drlearner\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- ATE pour le metalearner Slearner = -88.50578431129637.\n",
      "- ATE pour le metalearner TLearner = -89.02184983914371.\n",
      "- ATE pour le metalearner XLearner = -89.25197482587703.\n",
      "- ATE pour le metalearner DRLearner = -88.78615131608478.\n"
     ]
    }
   ],
   "source": [
    "results = np.zeros((4,1))\n",
    "for j,(name, metalearner) in enumerate(metalearners.items()):\n",
    "    metalearner.fit(X,W,Y)\n",
    "    if name == 'XLearner':\n",
    "        cls = LogisticRegression()\n",
    "        cls = CalibratedClassifierCV(cls)\n",
    "        cls.fit(X, W)\n",
    "        propensity = cls.predict_proba(X)[:,1]\n",
    "        cate_hat_T = metalearner.predict_CATE(X,propensity)\n",
    "    else:\n",
    "        cate_hat_T = metalearner.predict_CATE(X)\n",
    "    ate_hat_T = metalearner.predict_ATE()\n",
    "    print(\"- ATE pour le metalearner {} = {}.\".format(name, ate_hat_T))\n",
    "    results[j]= ate_hat_T\n",
    "df.iloc[i] = results.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SLearner</th>\n",
       "      <th>TLearner</th>\n",
       "      <th>XLearner</th>\n",
       "      <th>DRLearner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.5</th>\n",
       "      <td>-90.049942</td>\n",
       "      <td>-90.049906</td>\n",
       "      <td>-90.049906</td>\n",
       "      <td>-90.049984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>-89.920028</td>\n",
       "      <td>-89.889912</td>\n",
       "      <td>-90.139028</td>\n",
       "      <td>-89.994851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hybrid</th>\n",
       "      <td>-88.505784</td>\n",
       "      <td>-89.02185</td>\n",
       "      <td>-89.251975</td>\n",
       "      <td>-88.786151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         SLearner   TLearner   XLearner  DRLearner\n",
       "0.5    -90.049942 -90.049906 -90.049906 -90.049984\n",
       "0.1    -89.920028 -89.889912 -90.139028 -89.994851\n",
       "hybrid -88.505784  -89.02185 -89.251975 -88.786151"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "simulation_model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
